{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-optimize\n",
    "# !pip install sktime\n",
    "# !pip install tensorflow --user\n",
    "# !pip install statsmodels --user\n",
    "# !pip install xgboost --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from datetime import datetime as dt\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    mean_squared_error, \n",
    "    mean_absolute_error, \n",
    "    mean_absolute_percentage_error, \n",
    "    r2_score, \n",
    "    mean_squared_log_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, \n",
    "    GradientBoostingRegressor, \n",
    "    ExtraTreesRegressor, \n",
    "    AdaBoostRegressor\n",
    ")\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, DotProduct, WhiteKernel\n",
    "import xgboost as xgb\n",
    "\n",
    "# Time series libraries\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_breusch_godfrey, acorr_ljungbox, het_white\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import acf, q_stat, adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAXResults\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from arch import arch_model\n",
    "import pmdarima as pm\n",
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "from sktime.forecasting.model_selection import ForecastingGridSearchCV, SlidingWindowSplitter\n",
    "\n",
    "#Libraries for Statistical Models\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import acorr_breusch_godfrey, acorr_ljungbox, het_white\n",
    "from scipy.stats import jarque_bera\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf, q_stat, adfuller\n",
    "from scipy.stats import probplot, moment\n",
    "\n",
    "# LightGBM library\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Set options\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add date tiem features\n",
    "def add_datetime_features(df):\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Extract year, month, and day information\n",
    "    df_copy['year'] = df_copy.index.year\n",
    "    df_copy['month'] = df_copy.index.month\n",
    "    df_copy['day'] = df_copy.index.day\n",
    "    df_copy['weekday'] = df_copy.index.weekday\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def generate_lagged_features(df, var, max_lag):\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "    ts_data = df.copy()\n",
    "    for t in range(1, max_lag + 1):\n",
    "        ts_data[var + '_lag' + str(t)] = ts_data[var].shift(t, freq='1D')\n",
    "    # print(ts_data.head())\n",
    "    # print(ts_data.tail())\n",
    "    # print(ts_data.shape)\n",
    "    ts_data.dropna(inplace=True)\n",
    "\n",
    "    return ts_data\n",
    "\n",
    "# def prepare_time_series_data(df, var, max_lag):\n",
    "#     # Generate lagged features\n",
    "#     lagged_data = generate_lagged_features(df, var, max_lag)\n",
    "    \n",
    "#     # Add datetime features\n",
    "#     if not isinstance(lagged_data.index, pd.DatetimeIndex):\n",
    "#         lagged_data.index = pd.to_datetime(lagged_data.index)\n",
    "#     transformed_data = add_datetime_features(lagged_data)\n",
    "    \n",
    "#     return transformed_data\n",
    "\n",
    "def extract_column(df, column_name):\n",
    "    extracted_column = df[column_name]\n",
    "    remaining_df = df.drop(column_name, axis=1)\n",
    "    return remaining_df, extracted_column\n",
    "\n",
    "# def scale_data(train_data, test_data):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     train_scaled = scaler.fit_transform(train_data)\n",
    "#     test_scaled = scaler.transform(test_data)\n",
    "#     return train_scaled, test_scaled, scaler\n",
    "\n",
    "# def scale_data(train_data, test_data, target_column):\n",
    "#     scaler_X = MinMaxScaler()\n",
    "#     scaler_Y = MinMaxScaler()\n",
    "    \n",
    "#     train_X = train_data.drop(target_column, axis=1)\n",
    "#     train_Y = train_data[[target_column]]\n",
    "    \n",
    "#     test_X = test_data.drop(target_column, axis=1)\n",
    "#     test_Y = test_data[[target_column]]\n",
    "    \n",
    "#     train_X_scaled = scaler_X.fit_transform(train_X)\n",
    "#     train_Y_scaled = scaler_Y.fit_transform(train_Y)\n",
    "    \n",
    "#     test_X_scaled = scaler_X.transform(test_X)\n",
    "#     test_Y_scaled = scaler_Y.transform(test_Y)\n",
    "    \n",
    "#     train_data_scaled = np.concatenate((train_X_scaled, train_Y_scaled), axis=1)\n",
    "#     test_data_scaled = np.concatenate((test_X_scaled, test_Y_scaled), axis=1)\n",
    "    \n",
    "#     return train_data_scaled, test_data_scaled, scaler_X, scaler_Y\n",
    "\n",
    "\n",
    "def scale_data(train_data, test_data, target_column):\n",
    "    # scaler_X = MinMaxScaler()\n",
    "    # scaler_Y = MinMaxScaler()\n",
    "    # scaler_X = StandardScaler()\n",
    "    # scaler_Y = StandardScaler() \n",
    "    scaler_X = RobustScaler()\n",
    "    scaler_Y = RobustScaler()   \n",
    "    \n",
    "    train_X = train_data.drop(target_column, axis=1)\n",
    "    # print(train_X)\n",
    "    # train_X = train_data\n",
    "    train_Y = train_data[[target_column]]\n",
    "    # print(train_Y)\n",
    "    test_X = test_data.drop(target_column, axis=1)\n",
    "    # test_X = test_data\n",
    "    test_Y = test_data[[target_column]]\n",
    "    # print('xscaled')\n",
    "    train_X_scaled = scaler_X.fit_transform(train_X)\n",
    "    # print(train_X_scaled.shape)\n",
    "    train_Y_scaled = scaler_Y.fit_transform(train_Y)\n",
    "    # print('yscaled')\n",
    "    # print(train_Y_scaled.shape)\n",
    "    test_X_scaled = scaler_X.transform(test_X)\n",
    "    test_Y_scaled = scaler_Y.transform(test_Y)\n",
    "    \n",
    "    # train_data_scaled = np.concatenate((train_X_scaled, train_Y_scaled), axis=1)\n",
    "    # test_data_scaled = np.concatenate((test_X_scaled, test_Y_scaled), axis=1)\n",
    "    train_data_scaled = pd.concat([pd.DataFrame(train_X_scaled, columns=train_X.columns, index=train_X.index),\n",
    "                                pd.DataFrame(train_Y_scaled, columns=train_Y.columns, index=train_Y.index)], axis=1)\n",
    "    test_data_scaled = pd.concat([pd.DataFrame(test_X_scaled, columns=test_X.columns, index=test_X.index),\n",
    "                                pd.DataFrame(test_Y_scaled, columns=test_Y.columns, index=test_Y.index)], axis=1)\n",
    "\n",
    "\n",
    "    # print(train_data_scaled.shape)\n",
    "    return train_data_scaled, test_data_scaled, scaler_X, scaler_Y\n",
    "\n",
    "\n",
    "def unscale_data(pred, actual, scaler):\n",
    "    pred = scaler.inverse_transform(pred)\n",
    "    actual = scaler.inverse_transform(actual)\n",
    "    return pred, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_series(series):\n",
    "    return StandardScaler().fit_transform(series.values.reshape(-1, 1))\n",
    "\n",
    "def apply_dbscan_clustering(series_standardized, eps=0.5, min_samples=2):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    return dbscan.fit_predict(series_standardized)\n",
    "\n",
    "def extract_outliers_from_clusters(series, clusters):\n",
    "    \"\"\"Identify the outliers (cluster label -1 indicates an outlier)\"\"\"\n",
    "    return series[clusters == -1]\n",
    "\n",
    "def cluster_based_outlier_detection(series):\n",
    "    series_standardized = standardize_series(series)\n",
    "    clusters = apply_dbscan_clustering(series_standardized, eps=0.15)\n",
    "    outliers = extract_outliers_from_clusters(series, clusters)\n",
    "    print('Outliers shape: {}'.format(outliers.shape))\n",
    "    # Create a DataFrame with the same index as the original series\n",
    "    outliers_df = pd.DataFrame(index=series.index)\n",
    "    outliers_df['outliers'] = 0\n",
    "    outliers_df.loc[outliers.index, 'outliers'] = 1\n",
    "\n",
    "    return outliers_df\n",
    "    \n",
    "# def prepare_time_series_data(df, var, max_lag, detect_outliers=False):\n",
    "#     # Generate lagged features\n",
    "#     lagged_data = generate_lagged_features(df, var, max_lag)\n",
    "#     # print('Lagged data shape: {}'.format(lagged_data.shape))\n",
    "    \n",
    "#     # Add outlier features if detect_outliers is True\n",
    "#     if detect_outliers:\n",
    "#         series = df[var].pow(2)\n",
    "#         series.dropna(inplace=True)  \n",
    "#         # print('Series shape: {}'.format(series.shape))\n",
    "#         outliers_df = cluster_based_outlier_detection(series)\n",
    "#         # print('Outliers DataFrame shape: {}'.format(outliers_df.shape))\n",
    "#         lagged_outliers = generate_lagged_features(outliers_df, 'outliers', max_lag)\n",
    "#         # print('Lagged outliers shape: {}'.format(lagged_outliers.shape))\n",
    "#         lagged_data = lagged_data.merge(lagged_outliers, left_index=True, right_index=True)\n",
    "#         # print('Lagged data shape: {}'.format(lagged_data.shape))\n",
    "\n",
    "#     # Add datetime features\n",
    "#     if not isinstance(lagged_data.index, pd.DatetimeIndex):\n",
    "#         lagged_data.index = pd.to_datetime(lagged_data.index)\n",
    "#     transformed_data = add_datetime_features(lagged_data)\n",
    "\n",
    "#     # Drop rows with missing values\n",
    "#     transformed_data.dropna(inplace=True)\n",
    "\n",
    "#     return transformed_data\n",
    "def prepare_time_series_data(df, var, max_lag, detect_outliers=False):\n",
    "    # Generate lagged features\n",
    "    lagged_data = generate_lagged_features(df, var, max_lag)\n",
    "    # print('Lagged data shape: {}'.format(lagged_data.shape))\n",
    "    \n",
    "    # Add outlier features if detect_outliers is True\n",
    "    if detect_outliers:\n",
    "        series = df[var].pow(2)\n",
    "        series.dropna(inplace=True)  \n",
    "        # print('Series shape: {}'.format(series.shape))\n",
    "        outliers_df = cluster_based_outlier_detection(series)\n",
    "        # print('Outliers DataFrame shape: {}'.format(outliers_df.shape))\n",
    "        lagged_outliers = generate_lagged_features(outliers_df, 'outliers', max_lag)\n",
    "        # print('Lagged outliers shape: {}'.format(lagged_outliers.shape))\n",
    "        lagged_data = lagged_data.merge(lagged_outliers, left_index=True, right_index=True)\n",
    "        # print('Lagged data shape: {}'.format(lagged_data.shape))\n",
    "\n",
    "    # Add datetime features\n",
    "    if not isinstance(lagged_data.index, pd.DatetimeIndex):\n",
    "        lagged_data.index = pd.to_datetime(lagged_data.index)\n",
    "    # transformed_data = add_datetime_features(lagged_data)\n",
    "    transformed_data = lagged_data\n",
    "    # Drop rows with missing values\n",
    "    transformed_data.dropna(inplace=True)\n",
    "\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    # msle = mean_squared_log_error(y_true, y_pred)\n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "    }\n",
    "\n",
    "def perform_grid_search(model, param_grid, X_train, Y_train, cv):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=3,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    cv_results = grid_search.cv_results_\n",
    "    mean_score = -np.mean(cv_results['mean_test_score'])\n",
    "    std_score = np.std(cv_results['mean_test_score'])\n",
    "    \n",
    "    # Take the square root of the mean_score and std_score\n",
    "    rmse_mean = np.sqrt(mean_score)\n",
    "    rmse_std = np.sqrt(std_score)\n",
    "    \n",
    "    return best_model, rmse_mean, rmse_std\n",
    "\n",
    "def train_best_model(best_model, X_train, Y_train):\n",
    "    best_model.fit(X_train, Y_train)\n",
    "    return best_model\n",
    "\n",
    "def predict(model, X):\n",
    "    return model.predict(X)\n",
    "\n",
    "def reshape_and_unscale_predictions(preds, actuals, scaler_Y):\n",
    "    # Reshape predictions and actual values for unscaling\n",
    "    preds_reshaped = preds.reshape(-1, 1)\n",
    "    actuals_reshaped = actuals.values.reshape(-1, 1)\n",
    "\n",
    "    # Unscale the predictions and actual values\n",
    "    unscaled_preds, unscaled_actuals = unscale_data(preds_reshaped, actuals_reshaped, scaler_Y)\n",
    "\n",
    "    # Convert the unscaled predictions and actuals back to pandas Series\n",
    "    unscaled_preds_series = pd.Series(unscaled_preds.squeeze(), index=actuals.index)\n",
    "    unscaled_actuals_series = pd.Series(unscaled_actuals.squeeze(), index=actuals.index)\n",
    "\n",
    "    return unscaled_preds_series, unscaled_actuals_series\n",
    "\n",
    "    \n",
    "def create_directory_if_not_exists(directory):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "\n",
    "def save_plots_for_experiment(experiment, hypothesis, model_name, train_or_test, plot_type):\n",
    "    # Create the necessary directories\n",
    "    experiment_path = os.path.join(hypothesis, experiment, train_or_test)\n",
    "    create_directory_if_not_exists(experiment_path)\n",
    "    \n",
    "    # Return the save path\n",
    "    save_path = os.path.join(experiment_path, f\"{model_name}_{plot_type}.png\")\n",
    "    return save_path\n",
    "\n",
    "    \n",
    "def model_pipeline(model, param_grid, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, model_name,experiment, show_plot=False):\n",
    "    \n",
    "    # Perform grid search\n",
    "    best_model, rmean_error_train, std_error = perform_grid_search(model, param_grid, X_train, Y_train, tscv)\n",
    "    \n",
    "    print(\"\\nBest model:\", best_model)\n",
    "    print(\"\\nMean error:\", rmean_error_train)\n",
    "    print(\"\\nStandard error:\", std_error)\n",
    "    \n",
    "    # Train best model on all training data\n",
    "    best_model_trained = train_best_model(best_model, X_train, Y_train)\n",
    "    \n",
    "    # Predict on train set\n",
    "    train_preds = predict(best_model_trained, X_train)\n",
    "    \n",
    "    # Unscale and plot predictions vs actuals for train set\n",
    "    unscaled_preds_series, unscaled_actuals_series = reshape_and_unscale_predictions(train_preds, Y_train, scaler_Y)\n",
    "    save_path = save_plots_for_experiment(experiment, hypothesis, model_name, \"train\", \"predictions_vs_actuals\")\n",
    "    plot_series(unscaled_actuals_series, unscaled_preds_series, title=\"Unscaled Predictions vs Actual Training Data\", save_path=save_path, show_plot=show_plot)\n",
    "\n",
    "    # Perform residual analysis for train set\n",
    "    residuals_train = unscaled_actuals_series - unscaled_preds_series\n",
    "    print(\"\\nResidual analysis for train set:\")\n",
    "    save_path = save_plots_for_experiment(experiment, hypothesis, model_name, \"train\", \"correlogram\")\n",
    "    plot_correlogram(residuals_train, save_path=save_path, show_plot=show_plot)\n",
    "    save_path = save_plots_for_experiment(experiment, hypothesis, model_name, \"train\", \"homoskedasticity_plot\")\n",
    "    residual_analysis(residuals_train, unscaled_preds_series, save_path=save_path)\n",
    "    print(\"\\nResiduals squared\\n\")\n",
    "    save_path = save_plots_for_experiment(experiment, hypothesis, model_name, \"train\", \"correlogram_squared\")\n",
    "    plot_correlogram(residuals_train.pow(2), save_path=save_path, show_plot=False)\n",
    "    residual_analysis(residuals_train.pow(2), unscaled_preds_series.pow(2), save_path=None)\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_preds = predict(best_model_trained, X_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(Y_test, test_preds))\n",
    "    print(\"RMSE:\", rmse_test)\n",
    "    \n",
    "    # Unscale and plot predictions vs actuals for test set\n",
    "    unscaled_preds_series, unscaled_actuals_series = reshape_and_unscale_predictions(test_preds, Y_test, scaler_Y)\n",
    "    save_path = save_plots_for_experiment(experiment, hypothesis, model_name, \"test\", \"predictions_vs_actuals\")\n",
    "    plot_series(unscaled_actuals_series, unscaled_preds_series, title=\"Unscaled Predictions vs Actual Test Data\", save_path=save_path, show_plot=show_plot)\n",
    "\n",
    "    # Perform residual analysis for test set\n",
    "    residuals_test = unscaled_actuals_series - unscaled_preds_series\n",
    "    print(\"\\nResidual analysis for test set:\")\n",
    "    save_path = save_plots_for_experiment(experiment, hypothesis, model_name, \"test\", \"correlogram\")\n",
    "    plot_correlogram(residuals_test, save_path=save_path, show_plot=show_plot)\n",
    "    save_path = save_plots_for_experiment(experiment, hypothesis, model_name, \"test\", \"homoskedasticity_plot\")\n",
    "    residual_analysis(residuals_test, unscaled_preds_series, save_path=save_path)\n",
    "    print(\"\\nResiduals squared\\n\")\n",
    "    save_path = save_plots_for_experiment(experiment, hypothesis, model_name, \"test\", \"correlogram_squared\")\n",
    "    plot_correlogram(residuals_test.pow(2), title='Residuals Squared', save_path=save_path, show_plot=False)\n",
    "    residual_analysis(residuals_test.pow(2), unscaled_preds_series.pow(2), save_path=None)\n",
    "\n",
    "    return best_model_trained , rmean_error_train, rmse_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(series1, series2, label1=\"Actual\", label2=\"Predicted\", title=\"Unscaled Predictions vs Actual Data\", save_path=None, show_plot=False):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(series1.index, series1, label=label1)\n",
    "    ax.plot(series2.index, series2, label=label2, linestyle=\"--\")\n",
    "    ax.legend()\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(title)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_correlogram(x, lags=None, title=None,save_path=None, show_plot=False):\n",
    "    lags = min(10, int(len(x)/5)) if lags is None else lags\n",
    "    x = x + np.random.normal(0, 1e-10, len(x)) ## Add noise to avoid non-invertibility\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 8))\n",
    "    \n",
    "    # Residuals plot\n",
    "    x.plot(ax=axes[0][0], title='Residuals')\n",
    "    x.rolling(21).mean().plot(ax=axes[0][0], c='k', lw=1)\n",
    "    q_p = np.max(q_stat(acf(x, nlags=lags), len(x))[1])\n",
    "    stats = f'Q-Stat: {np.max(q_p):>8.2f}\\nADF: {adfuller(x)[1]:>11.2f}'\n",
    "    axes[0][0].text(x=.02, y=.85, s=stats, transform=axes[0][0].transAxes)\n",
    "    \n",
    "    # Probability plot\n",
    "    probplot(x, plot=axes[0][1])\n",
    "    mean, var, skew, kurtosis = moment(x, moment=[1, 2, 3, 4])\n",
    "    s = f'Mean: {mean:>12.2f}\\nSD: {np.sqrt(var):>16.2f}\\nSkew: {skew:12.2f}\\nKurtosis:{kurtosis:9.2f}'\n",
    "    axes[0][1].text(x=.02, y=.75, s=s, transform=axes[0][1].transAxes)\n",
    "    \n",
    "    # ACF and PACF plots\n",
    "    plot_acf(x=x, lags=lags, zero=False, ax=axes[1][0])\n",
    "    plot_pacf(x, lags=lags, zero=False, ax=axes[1][1])\n",
    "    axes[1][0].set_xlabel('Lag')\n",
    "    axes[1][1].set_xlabel('Lag')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    sns.despine()\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=.9)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "def residual_analysis(residuals, y_pred, save_path=None):\n",
    "    \n",
    "    # Check for homoscedasticity\n",
    "    print(\"Homoscedasticity scatter plot:\")\n",
    "    plt.scatter(y_pred, residuals)\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Perform Ljung-Box test for autocorrelation in residuals\n",
    "    lb_test = acorr_ljungbox(residuals, lags=[10], return_df=True)  \n",
    "    print(\"Ljung-Box test for autocorrelation in residuals:\")\n",
    "    print(lb_test)\n",
    "    # Assess the p-value of the Ljung-Box test\n",
    "    p_value = lb_test['lb_pvalue'][10]\n",
    "    if p_value < 0.05:\n",
    "        print(\"The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\")\n",
    "    else:\n",
    "        print(\"The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\")\n",
    "    \n",
    "    # Perform Jarque-Bera test for normality in residuals\n",
    "    jb_test = jarque_bera(residuals)\n",
    "    print(\"\\nJarque-Bera test for normality in residuals:\")\n",
    "    if jb_test[1] < 0.05:\n",
    "        print(f\"Test statistic: {jb_test[0]}, p-value: {jb_test[1]}\")\n",
    "        print(\"The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\")\n",
    "    else:\n",
    "        print(f\"Test statistic: {jb_test[0]}, p-value: {jb_test[1]}\")\n",
    "        print(\"The Jarque-Bera test suggests that the residuals are normally distributed (p-value >= 0.05).\")    \n",
    "        \n",
    "def plot_rmse_comparison(results, hypothesis, experiment):\n",
    "    fig = plt.figure()\n",
    "    model_names = list(results.keys())\n",
    "    train_rmse_values = [result['train_rmse'] for result in results.values()]\n",
    "    test_rmse_values = [result['test_rmse'] for result in results.values()]\n",
    "\n",
    "    ind = np.arange(len(model_names))  # the x locations for the groups\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig.suptitle('Algorithm Comparison')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.bar(ind - width/2, train_rmse_values, width=width, label='Train Error')\n",
    "    plt.bar(ind + width/2, test_rmse_values, width=width, label='Test Error')\n",
    "    fig.set_size_inches(15, 8)\n",
    "    plt.legend()\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(model_names)\n",
    "    \n",
    "    # Save the plot\n",
    "    save_path = save_plots_for_experiment(experiment, hypothesis, \"Results\", \"\", \"Model_Comparison\")\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    \n",
    "def plot_rmse_comparison_hypothesis(hypothesis_results):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.suptitle('Algorithm Comparison')\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    n_experiments = len(hypothesis_results)\n",
    "    model_names = list(next(iter(hypothesis_results.values())).keys())\n",
    "    n_models = len(model_names)\n",
    "    width = 0.8 / (n_models * 2)  # the width of the bars\n",
    "\n",
    "    x = np.arange(n_experiments) * (n_models * 2 + 1)  # the x locations for the groups\n",
    "\n",
    "    for i, (model_name) in enumerate(model_names):\n",
    "        for j, (experiment, results) in enumerate(hypothesis_results.items()):\n",
    "            train_rmse = results[model_name]['train_rmse']\n",
    "            test_rmse = results[model_name]['test_rmse']\n",
    "\n",
    "            ax.bar(x[j] + i * width * 2, train_rmse, width=width, label=f\"{model_name} Train Error\",color=colors[i % len(colors)])\n",
    "            ax.bar(x[j] + i * width * 2 + width, test_rmse, width=width, label=f\"{model_name} Test Error\",color=colors[i % len(colors)])\n",
    "\n",
    "    fig.set_size_inches(15, 8)\n",
    "    plt.legend()\n",
    "    ax.set_xticks(x + width * (n_models - 1))\n",
    "    ax.set_xticklabels(hypothesis_results.keys())\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    # Save the plot\n",
    "    # save_path = save_plots_for_experiment(\"\", hypothesis, \"Results\", \"\", \"Model_Comparison\")\n",
    "    # if save_path:\n",
    "    #     plt.savefig(save_path)\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rw(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    msle = mean_squared_log_error(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape,\n",
    "        'r2': r2,\n",
    "        'msle': msle,\n",
    "    }\n",
    "\n",
    "# univaritae\n",
    "## Simple models for benchmarking\n",
    "def random_walk_forecast(start_point, forecast_length, return_mean, return_std, index):\n",
    "    prediction = [start_point]\n",
    "\n",
    "    for i in range(1, forecast_length):\n",
    "        next_value = prediction[-1] * (1 + random.normalvariate(mu=return_mean, sigma=return_std))\n",
    "        prediction.append(next_value)\n",
    "\n",
    "    return pd.Series(prediction, index=index)\n",
    "\n",
    "def calculate_benchmark_errors(series):\n",
    "    mean_returns, std_returns = calculate_returns_stats(series)\n",
    "    forecast_length = len(series)\n",
    "    start_point = series[0]\n",
    "    predictions = random_walk_forecast(start_point, forecast_length, mean_returns, std_returns, series.index)\n",
    "    # print(predictions)\n",
    "    evaluation_result = evaluate_rw(series, predictions)\n",
    "    # Return a dictionary containing the evaluation results for each baseline\n",
    "    return {\n",
    "        'Benchmark MAE': evaluation_result['mae'],\n",
    "        'Benchmark MSE': evaluation_result['mse'],\n",
    "        'Benchmark RMSE': evaluation_result['rmse'],\n",
    "        'Benchmark MAPE': evaluation_result['mape'],\n",
    "        'Benchmark R2': evaluation_result['r2'],\n",
    "        'Benchmark MSLE': evaluation_result['msle'],\n",
    "    }\n",
    "\n",
    "def calculate_returns_stats(time_series):\n",
    "    # Calculate the returns\n",
    "    returns = time_series / time_series.shift(1) - 1\n",
    "    returns = returns.dropna()\n",
    "\n",
    "    # Calculate mean returns and standard deviation of returns\n",
    "    mean_returns = returns.mean()\n",
    "    std_returns = returns.std()\n",
    "\n",
    "    return mean_returns, std_returns\n",
    "\n",
    "# multivariate\n",
    "def random_walk_forecast_multivariate(start_points, forecast_length, return_means, return_stds, index):\n",
    "    num_variables = len(start_points)\n",
    "    predictions = [start_points]\n",
    "\n",
    "    for _ in range(1, forecast_length):\n",
    "        next_values = [predictions[-1][i] * (1 + random.normalvariate(mu=return_means[i], sigma=return_stds[i])) for i in range(num_variables)]\n",
    "        predictions.append(next_values)\n",
    "\n",
    "    # Transpose the list of predictions and convert each variable's predictions to a pandas Series\n",
    "    predictions_transposed = list(map(list, zip(*predictions)))\n",
    "    prediction_series = [pd.Series(pred, index=index) for pred in predictions_transposed]\n",
    "\n",
    "    return prediction_series\n",
    "\n",
    "def calculate_benchmark_errors_mult(series1, series2):\n",
    "    mean_returns1, std_returns1 = calculate_returns_stats(series1)\n",
    "    mean_returns2, std_returns2 = calculate_returns_stats(series2)\n",
    "    \n",
    "    forecast_length = len(series1)\n",
    "    start_points = [series1[0], series2[0]]\n",
    "    return_means = [mean_returns1, mean_returns2]\n",
    "    return_stds = [std_returns1, std_returns2]\n",
    "    \n",
    "    predictions = random_walk_forecast_multivariate(start_points, forecast_length, return_means, return_stds, series1.index)\n",
    "    \n",
    "    evaluation_result1 = evaluate_rw(series1, predictions[0])\n",
    "    evaluation_result2 = evaluate_rw(series2, predictions[1])\n",
    "    # plot_time_series(series1, predictions[0])\n",
    "    # plot_time_series(series2, predictions[1])\n",
    "    \n",
    "    return {\n",
    "        'Series1 Benchmark MAE': evaluation_result1['mae'],\n",
    "        'Series1 Benchmark MSE': evaluation_result1['mse'],\n",
    "        'Series1 Benchmark RMSE': evaluation_result1['rmse'],\n",
    "        'Series1 Benchmark MAPE': evaluation_result1['mape'],\n",
    "        'Series1 Benchmark R2': evaluation_result1['r2'],\n",
    "        'Series1 Benchmark MSLE': evaluation_result1['msle'],\n",
    "        'Series2 Benchmark MAE': evaluation_result2['mae'],\n",
    "        'Series2 Benchmark MSE': evaluation_result2['mse'],\n",
    "        'Series2 Benchmark RMSE': evaluation_result2['rmse'],\n",
    "        'Series2 Benchmark MAPE': evaluation_result2['mape'],\n",
    "        'Series2 Benchmark R2': evaluation_result2['r2'],\n",
    "        'Series2 Benchmark MSLE': evaluation_result2['msle'],\n",
    "    }\n",
    "    \n",
    "def monte_carlo_simulation(series, n_trials=10000):\n",
    "    # Initialize a dictionary to store the accumulated evaluation results\n",
    "    accumulated_results = {\n",
    "        'Benchmark MAE': 0,\n",
    "        'Benchmark MSE': 0,\n",
    "        'Benchmark RMSE': 0,\n",
    "        'Benchmark MAPE': 0,\n",
    "        'Benchmark R2': 0,\n",
    "        'Benchmark MSLE': 0,\n",
    "    }\n",
    "\n",
    "    for _ in range(n_trials):\n",
    "        # Calculate benchmark errors for this trial\n",
    "        trial_results = calculate_benchmark_errors(series)\n",
    "\n",
    "        # Accumulate the results of this trial\n",
    "        for key in accumulated_results.keys():\n",
    "            accumulated_results[key] += trial_results[key]\n",
    "\n",
    "    # Average the accumulated results over the number of trials\n",
    "    for key in accumulated_results.keys():\n",
    "        accumulated_results[key] /= n_trials\n",
    "\n",
    "    return accumulated_results\n",
    "    \n",
    "def monte_carlo_simulation_mult(series1, series2, n_trials=10000):\n",
    "    # Initialize a dictionary to store the accumulated evaluation results\n",
    "    accumulated_results = {\n",
    "        'Series1 Benchmark MAE': 0,\n",
    "        'Series1 Benchmark MSE': 0,\n",
    "        'Series1 Benchmark RMSE': 0,\n",
    "        'Series1 Benchmark MAPE': 0,\n",
    "        'Series1 Benchmark R2': 0,\n",
    "        'Series1 Benchmark MSLE': 0,\n",
    "        'Series2 Benchmark MAE': 0,\n",
    "        'Series2 Benchmark MSE': 0,\n",
    "        'Series2 Benchmark RMSE': 0,\n",
    "        'Series2 Benchmark MAPE': 0,\n",
    "        'Series2 Benchmark R2': 0,\n",
    "        'Series2 Benchmark MSLE': 0,\n",
    "    }\n",
    "\n",
    "    for _ in range(n_trials):\n",
    "        # Calculate benchmark errors for this trial\n",
    "        trial_results = calculate_benchmark_errors_mult(series1, series2)\n",
    "\n",
    "        # Accumulate the results of this trial\n",
    "        for key in accumulated_results.keys():\n",
    "            accumulated_results[key] += trial_results[key]\n",
    "\n",
    "    # Average the accumulated results over the number of trials\n",
    "    for key in accumulated_results.keys():\n",
    "        accumulated_results[key] /= n_trials\n",
    "\n",
    "    return accumulated_results\n",
    "    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_param_grids = [\n",
    "    {\n",
    "        'model': DecisionTreeRegressor(random_state=42),\n",
    "        'param_grid': {\n",
    "            'max_depth': [None, 10, 20, 30,50],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'max_features': ['auto'],\n",
    "            'min_samples_leaf': [1, 3, 5, 10]\n",
    "        },\n",
    "        'model_name': 'CART',\n",
    "    },\n",
    "    # {\n",
    "    #     'model': MLPRegressor(random_state=42),\n",
    "    #     'param_grid': {\n",
    "    #         'hidden_layer_sizes': [(50,), (100,), (50, 50),(100, 100), (50, 50, 50), (100, 100, 100), (50, 50, 50, 50), (100, 100, 100, 100)],\n",
    "    #         'activation': ['tanh', 'relu', 'logistic'],\n",
    "    #         'solver': ['sgd'],\n",
    "    #         'alpha': [0.00005, 0.0005, 0.005],\n",
    "    #         'early_stopping': [True],\n",
    "    #         'max_iter': [600],\n",
    "    #         'shuffle': [False],\n",
    "    #     },\n",
    "    #     'model_name': 'MLP',\n",
    "    # },\n",
    "    {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'param_grid': {\n",
    "            'n_neighbors': [3, 5, 7, 9, 11],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto'],\n",
    "            'leaf_size': [10, 30, 50],\n",
    "        },\n",
    "        'model_name': 'KNN',\n",
    "    },\n",
    "    # {\n",
    "    #     'model': GaussianProcessRegressor(random_state=42),\n",
    "    #     'param_grid': {\n",
    "    #         'kernel': [RBF(), DotProduct()+ WhiteKernel()],\n",
    "    #         'alpha': [1e-10, 1e-5, 1e-2, 1],\n",
    "    #         'n_restarts_optimizer': [0, 1, 3],\n",
    "    #     },\n",
    "    #     'model_name': 'GPR',\n",
    "    # },\n",
    "    {\n",
    "        'model': lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42),\n",
    "        'param_grid': {\n",
    "            'lgbmregressor__n_estimators': [100],\n",
    "            'lgbmregressor__learning_rate': [0.01],\n",
    "            'lgbmregressor__max_depth': [5, 10, 20],\n",
    "            'lgbmregressor__num_leaves': [35, 50],\n",
    "        },\n",
    "        'model_name': 'GBR',\n",
    "    },\n",
    "        {\n",
    "        'model': xgb.XGBRegressor(random_state=42),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [100],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'min_child_weight': [1, 3, 5],\n",
    "        },\n",
    "        'model_name': 'XGB',\n",
    "    },\n",
    "    {\n",
    "        'model': RandomForestRegressor(random_state=42),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [10, 50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'max_features': ['auto'],\n",
    "        },\n",
    "        'model_name': 'RF',\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(train_data, test_data, lags, input_column, target_column, detect_outliers = False):\n",
    "    # Create new dataframes with input and target columns\n",
    "    input_train = train_data[[input_column]]\n",
    "    input_test = test_data[[input_column]]\n",
    "    input_train.columns = ['input']\n",
    "    input_test.columns = ['input']\n",
    "    target_train = train_data[[target_column]]\n",
    "    target_test = test_data[[target_column]]\n",
    "    target_train.columns = ['target']\n",
    "    target_test.columns = ['target']\n",
    "\n",
    "    train_data = pd.concat([input_train, target_train], axis=1)\n",
    "    test_data = pd.concat([input_test, target_test], axis=1)\n",
    "    train_data_datetime = add_datetime_features(train_data)\n",
    "    test_data_datetime = add_datetime_features(test_data)\n",
    "\n",
    "    # Scale the data\n",
    "    train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_data_datetime, test_data_datetime, 'target')\n",
    "\n",
    "    # Prepare time series data\n",
    "    train_transformed = prepare_time_series_data(train_data_scaled, 'input', lags, detect_outliers=detect_outliers)\n",
    "    test_transformed = prepare_time_series_data(test_data_scaled, 'input', lags, detect_outliers=detect_outliers)\n",
    "\n",
    "    # Drop the input column\n",
    "    train_transformed = train_transformed.drop('input', axis=1)\n",
    "    test_transformed = test_transformed.drop('input', axis=1)\n",
    "\n",
    "    # Extract X and Y\n",
    "    X_train, Y_train = extract_column(train_transformed, 'target')\n",
    "    X_test, Y_test = extract_column(test_transformed, 'target')\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test, scaler_X, scaler_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment):\n",
    "    results = {}\n",
    "\n",
    "    for model_info in models_and_param_grids:\n",
    "        model = model_info['model']\n",
    "        param_grid = model_info['param_grid']\n",
    "        model_name = model_info['model_name']\n",
    "        print(f\"\\nTraining {model_name} model...\")\n",
    "\n",
    "        best_model_trained, train_rmse, test_rmse = model_pipeline(\n",
    "            model, param_grid, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, model_name, experiment=experiment\n",
    "        )\n",
    "\n",
    "        results[model_name] = {\n",
    "            'model': best_model_trained,\n",
    "            'train_rmse': train_rmse,\n",
    "            'test_rmse': test_rmse,\n",
    "        }\n",
    "\n",
    "    print(\"\\nResults:\")\n",
    "    for model_name, model_results in results.items():\n",
    "        print(\n",
    "            f\"{model_name}: Train RMSE: {model_results['train_rmse']:.4f}, Test RMSE: {model_results['test_rmse']:.4f}\"\n",
    "        )\n",
    "\n",
    "    plot_rmse_comparison(results, hypothesis, experiment=experiment)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(filename):\n",
    "    raw_df = pd.read_csv(filename, header=None)\n",
    "    raw_df.columns = ['datetime', 'ts1', 'ts2']\n",
    "    raw_df['datetime'] = pd.to_datetime(raw_df['datetime'] - 719529, unit='d').round('s')\n",
    "    raw_df.set_index('datetime', inplace=True)\n",
    "    raw_df.dropna(inplace=True)\n",
    "    return raw_df\n",
    "\n",
    "def calculate_log_returns(df):\n",
    "    rt = np.log(df / df.shift(1))\n",
    "    rt.dropna(inplace=True)\n",
    "    return rt\n",
    "\n",
    "def load_clean_data(filename):\n",
    "    clean_df = pd.read_csv(filename)\n",
    "    clean_df.columns = ['datetime', 'ts1', 'ts2']\n",
    "    clean_df.set_index('datetime', inplace=True)\n",
    "    clean_df.index = pd.to_datetime(clean_df.index)\n",
    "    return clean_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_series(series, split_date):\n",
    "    series.index = pd.to_datetime(series.index)\n",
    "    split_date = pd.Timestamp(split_date)\n",
    "    \n",
    "    before_split = series.loc[series.index <= split_date]\n",
    "    after_split = series.loc[series.index > split_date]\n",
    "    \n",
    "    return before_split, after_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_raw_data(filename):\n",
    "#     raw_df = pd.read_csv(filename, header=None)\n",
    "#     raw_df.columns = ['datetime', 'ts1', 'ts2']\n",
    "#     raw_df['datetime'] = pd.to_datetime(raw_df['datetime'] - 719529, unit='d').round('s')\n",
    "#     raw_df.set_index('datetime', inplace=True)\n",
    "#     raw_df.dropna(inplace=True)\n",
    "#     return raw_df\n",
    "\n",
    "# def calculate_log_returns(df):\n",
    "#     rt = np.log(df / df.shift(1))\n",
    "#     rt.dropna(inplace=True)\n",
    "#     return rt\n",
    "\n",
    "# #load raw data\n",
    "# df = load_raw_data(\"Test_data.csv\")\n",
    "# #calcualte log returns\n",
    "# raw_rt = calculate_log_returns(df)\n",
    "# raw_rt_daily = raw_rt.resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   def load_clean_data(filename):\n",
    "#     clean_df = pd.read_csv(filename)\n",
    "#     clean_df.columns = ['datetime', 'ts1', 'ts2']\n",
    "#     clean_df.set_index('datetime', inplace=True)\n",
    "#     clean_df.index = pd.to_datetime(clean_df.index)\n",
    "#     return clean_df     \n",
    "\n",
    "# df = load_clean_data('interpolate_clean_df.csv')\n",
    "# #calcualte log returns\n",
    "# imp_rt = calculate_log_returns(df)\n",
    "# imp_rt_daily = imp_rt.resample('D').mean()\n",
    "\n",
    "\n",
    "# rt_d = pd.read_csv('rt_daily.csv')\n",
    "# rt_d.columns = ['datetime', 'ts1', 'ts2']\n",
    "# rt_d.set_index('datetime', inplace = True)\n",
    "# rt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load raw data\n",
    "df = load_raw_data(\"Test_data.csv\")\n",
    "#calcualte log returns\n",
    "raw_rt = calculate_log_returns(df)\n",
    "raw_rt_daily = raw_rt.resample('H').mean()\n",
    "\n",
    "df = load_clean_data('interpolate_clean_df.csv')\n",
    "#calcualte log returns\n",
    "imp_rt = calculate_log_returns(df)\n",
    "imp_rt_daily = imp_rt.resample('H').mean()\n",
    "\n",
    "# prerpare train and test experiments\n",
    "train_imp, test_imp = split_series(imp_rt_daily, '2011-12-31')\n",
    "train_raw, test_raw = split_series(raw_rt_daily, '2011-12-31')\n",
    "\n",
    "test_size = 24 \n",
    "n_splits = 30\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits, test_size=test_size)\n",
    "lags = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_leaf=10,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 2.138911793002859\n",
      "\n",
      "Standard error: 0.950220154760608\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  43.864431   0.000003\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 33492.935890556284, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  93.917347  8.923357e-16\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11720807.367721193, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.4643028564582221\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.893047   0.735502\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 17412.491155921918, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.588804    0.57152\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1918395.4549457442, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=50, n_neighbors=9)\n",
      "\n",
      "Mean error: 1.9576728648323642\n",
      "\n",
      "Standard error: 0.5088814399861655\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  46.822156   0.000001\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 49125.71344945184, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  145.063985  3.854256e-26\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 13821883.566950316, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.518616246085147\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.910253   0.822746\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 14063.069113722066, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.507523   0.579389\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1691388.5489912091, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.944979221608393\n",
      "\n",
      "Standard error: 0.0\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  46.551313   0.000001\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 26013.56953151378, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  59.965432  3.679298e-09\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 7299292.796156822, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.5147522065181682\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10  6.09423   0.807285\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 12908.979125494936, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10   7.7033   0.657793\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1641418.0902996506, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.8869215764371299\n",
      "\n",
      "Standard error: 0.21667049008769526\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  44.283909   0.000003\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 44477.057726198786, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  131.638354  2.163132e-23\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 7979227.373411719, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.4481977544332558\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  9.367977   0.497573\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 20328.479851986634, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.457772   0.584215\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1528349.6752315194, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', min_samples_split=10,\n",
      "                      n_estimators=10, random_state=42)\n",
      "\n",
      "Mean error: 1.9112490192666698\n",
      "\n",
      "Standard error: 0.29987174533276545\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  30.954256   0.000597\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 32610.608418179698, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  44.745276   0.000002\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 15782504.873511542, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.4862844493875058\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.644402    0.56615\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 19602.524583650906, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.347154   0.785303\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1290983.0222366755, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 2.1389, Test RMSE: 1.4643\n",
      "KNN: Train RMSE: 1.9577, Test RMSE: 1.5186\n",
      "GBR: Train RMSE: 1.9450, Test RMSE: 1.5148\n",
      "XGB: Train RMSE: 1.8869, Test RMSE: 1.4482\n",
      "RF: Train RMSE: 1.9112, Test RMSE: 1.4863\n",
      "Outliers shape: (17,)\n",
      "Outliers shape: (3,)\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_leaf=10,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 2.151455744436781\n",
      "\n",
      "Standard error: 0.9600346128779621\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  43.864431   0.000003\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 33492.93589055628, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  93.917347  8.923357e-16\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11720807.367721176, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.4643028564582223\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.893047   0.735502\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 17412.491155921918, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.588804    0.57152\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1918395.4549457442, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=50, n_neighbors=9)\n",
      "\n",
      "Mean error: 1.9596635590447165\n",
      "\n",
      "Standard error: 0.5025590857590548\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  47.612123  7.305142e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 49068.90993103382, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  140.650021  3.101086e-25\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 13922712.639740942, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.518616246085147\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.910253   0.822746\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 14063.069113722066, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.507523   0.579389\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1691388.5489912091, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.944979221608393\n",
      "\n",
      "Standard error: 0.0\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  46.551313   0.000001\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 26013.56953151378, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  59.965432  3.679298e-09\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 7299292.796156822, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.5147522065181682\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10  6.09423   0.807285\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 12908.979125494936, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10   7.7033   0.657793\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1641418.0902996506, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.8817917448032482\n",
      "\n",
      "Standard error: 0.20860521111909078\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  37.737337   0.000042\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 8684.368745205498, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  54.480094  3.948778e-08\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1219616.7168426164, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.4404679108583824\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  9.669499   0.469952\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 18977.40970904857, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.994452   0.725969\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1922685.784811802, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=20, max_features='auto', min_samples_split=10,\n",
      "                      n_estimators=200, random_state=42)\n",
      "\n",
      "Mean error: 1.9361546270027767\n",
      "\n",
      "Standard error: 0.36755699165965666\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  39.188155   0.000024\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 19881.103788091645, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  87.562631  1.627532e-14\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 6891868.648329556, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.451847595933648\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.266207   0.700097\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 19532.535004689096, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.741387   0.836503\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1654293.8448203646, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 2.1515, Test RMSE: 1.4643\n",
      "KNN: Train RMSE: 1.9597, Test RMSE: 1.5186\n",
      "GBR: Train RMSE: 1.9450, Test RMSE: 1.5148\n",
      "XGB: Train RMSE: 1.8818, Test RMSE: 1.4405\n",
      "RF: Train RMSE: 1.9362, Test RMSE: 1.4518\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', random_state=42)\n",
      "\n",
      "Mean error: 11.593515223166271\n",
      "\n",
      "Standard error: 8.598903933891414\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.182431   0.094528\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 205358780.2112115, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  23.735814   0.008333\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 769178943462.2194, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 67.25851581392378\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  9.471896   0.487979\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 16360.68429870647, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.427512   0.587153\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1358503.7375156535, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=50, n_neighbors=9)\n",
      "\n",
      "Mean error: 13.408928686530057\n",
      "\n",
      "Standard error: 8.933949039617058\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  46.171516   0.000001\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 120652600.77372415, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  119.509501  6.363153e-21\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 724709167790.3053, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.19172743842834\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  10.932257    0.36282\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 21949.8934812134, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.837982   0.740647\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1847464.0724718743, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 8.732149395230369\n",
      "\n",
      "Standard error: 1.1920928955078125e-07\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  64.175282  5.826917e-10\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 158444523.70371377, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  48.758033  4.510890e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 815255473027.2214, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.3005627263667\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  10.117305   0.430263\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 21269.39294166489, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.470744   0.774286\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1715058.6186052368, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 8.526640614651376\n",
      "\n",
      "Standard error: 0.6598727718941506\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  49.434357  3.390636e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 158111797.5545188, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  65.217104  3.683567e-10\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 869173134650.617, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.09070965432083\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  10.158848   0.426669\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 22105.915832016773, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.651944   0.843609\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1749953.4116801277, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', n_estimators=200,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 9.668092684672093\n",
      "\n",
      "Standard error: 5.157384741896749\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  30.312978   0.000761\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 85046671.2878678, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  70.359121  3.779325e-11\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 624106538695.7411, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.13038393055805\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  9.703039   0.466922\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 22932.862395058433, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.788593   0.832701\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1803093.0132765046, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 11.5935, Test RMSE: 67.2585\n",
      "KNN: Train RMSE: 13.4089, Test RMSE: 64.1917\n",
      "GBR: Train RMSE: 8.7321, Test RMSE: 64.3006\n",
      "XGB: Train RMSE: 8.5266, Test RMSE: 64.0907\n",
      "RF: Train RMSE: 9.6681, Test RMSE: 64.1304\n",
      "Outliers shape: (12,)\n",
      "Outliers shape: (3,)\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', random_state=42)\n",
      "\n",
      "Mean error: 11.424519512001567\n",
      "\n",
      "Standard error: 8.4587778397942\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  29.756555   0.000939\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1219477.4913963464, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  2387.611528        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 742496171.6823516, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 65.35971754708898\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10   8.8954   0.542058\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 20140.488763043453, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.648911   0.663088\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1425180.4543642574, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=50, n_neighbors=11)\n",
      "\n",
      "Mean error: 13.37632082637871\n",
      "\n",
      "Standard error: 8.94370285940955\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  49.365089  3.491345e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 137342035.52537566, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  83.170793  1.196751e-13\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 730782377444.1029, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.160473006739\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  10.920764   0.363724\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 21864.21520906001, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.539443   0.768091\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1842858.612193541, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 8.732149395230369\n",
      "\n",
      "Standard error: 1.1920928955078125e-07\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  64.175282  5.826917e-10\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 158444523.70371377, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  48.758033  4.510890e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 815255473027.2214, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.3005627263667\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  10.117305   0.430263\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 21269.39294166489, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.470744   0.774286\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1715058.6186052368, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 8.520075875214031\n",
      "\n",
      "Standard error: 0.4078415400234136\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  32.739234   0.000301\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 963576.8673958936, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  2746.673385        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 322512116.3522844, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.24670591111854\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  10.264351   0.417615\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 21830.017202141004, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.365232   0.783702\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1711740.498298389, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', n_estimators=200,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 9.355596608817967\n",
      "\n",
      "Standard error: 4.686066626286664\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  25.96428   0.003789\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 2117761.8477880033, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  2079.385977        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 8044602974.968284, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.17596000557958\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  10.096948   0.432029\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 22812.90698856758, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10  5.75519   0.835395\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1829975.0672424515, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 11.4245, Test RMSE: 65.3597\n",
      "KNN: Train RMSE: 13.3763, Test RMSE: 64.1605\n",
      "GBR: Train RMSE: 8.7321, Test RMSE: 64.3006\n",
      "XGB: Train RMSE: 8.5201, Test RMSE: 64.2467\n",
      "RF: Train RMSE: 9.3556, Test RMSE: 64.1760\n"
     ]
    }
   ],
   "source": [
    "#H1\n",
    "hypothesis = 'H1'\n",
    "hypothesis_results1 = {}\n",
    "# EX1\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_raw, test_raw, lags, detect_outliers=False, input_column='ts1', target_column='ts1')\n",
    "experiment = 'Raw_no_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results1[experiment] = results\n",
    "\n",
    "# EX2\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_raw, test_raw, lags, detect_outliers=True, input_column='ts1', target_column='ts1')\n",
    "experiment = 'Raw_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results1[experiment] = results\n",
    "\n",
    "# EX3\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_imp, test_raw, lags, detect_outliers=False, input_column='ts1', target_column='ts1')\n",
    "experiment = 'Imputed_no_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results1[experiment] = results\n",
    "\n",
    "# EX4 \n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_imp, test_raw, lags, detect_outliers=True, input_column='ts1', target_column='ts1')\n",
    "experiment = 'Impute_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results1[experiment] = results\n",
    "\n",
    "# Usage example:\n",
    "# plot_rmse_comparison_hypothesis(hypothesis_results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', random_state=42)\n",
      "\n",
      "Mean error: 2.011418313070749\n",
      "\n",
      "Standard error: 1.0893928625935259\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  17.198656   0.070082\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 163574.631606959, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  17.726708   0.059752\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 32326860.177385703, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.1595368013187455\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.435059   0.683833\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 77376.91612565839, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10  4.92132   0.896372\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 5949035.416708421, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=10, n_neighbors=11, weights='distance')\n",
      "\n",
      "Mean error: 1.6335053772877486\n",
      "\n",
      "Standard error: 0.36798723110401105\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10      NaN        NaN\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: nan, p-value: nan\n",
      "The Jarque-Bera test suggests that the residuals are normally distributed (p-value >= 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10      NaN        NaN\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: nan, p-value: nan\n",
      "The Jarque-Bera test suggests that the residuals are normally distributed (p-value >= 0.05).\n",
      "RMSE: 1.029278678070938\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10  7.52602   0.675025\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 10503.273793407021, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  14.63877   0.145797\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1043135.9641335538, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.6517902162036218\n",
      "\n",
      "Standard error: 0.0\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  55.622548  2.415647e-08\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 7948952.488848984, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat     lb_pvalue\n",
      "10  109.3794  7.117265e-19\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 766705452.1490958, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.064588528631299\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.215623   0.607784\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11630.561568046303, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  16.79513   0.079022\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1191684.8733523672, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.5036330856247075\n",
      "\n",
      "Standard error: 0.455877675518482\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  30.564991   0.000692\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 4026085.0370947607, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  193.979617  2.901675e-36\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 594963114.4555675, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.1009000684008625\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.103384   0.618739\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 128759.99325860378, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  4.708781   0.909764\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 10819397.98477489, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', min_samples_split=10,\n",
      "                      n_estimators=10, random_state=42)\n",
      "\n",
      "Mean error: 1.4908154726251452\n",
      "\n",
      "Standard error: 0.34791639495409926\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  23.397565   0.009371\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 217693.14146085843, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  476.119857  5.568632e-96\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 54163193.496816896, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.0295698255491876\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.870529   0.737609\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 15560.650916359522, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.428744   0.154318\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1101299.5715415766, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 2.0114, Test RMSE: 1.1595\n",
      "KNN: Train RMSE: 1.6335, Test RMSE: 1.0293\n",
      "GBR: Train RMSE: 1.6518, Test RMSE: 1.0646\n",
      "XGB: Train RMSE: 1.5036, Test RMSE: 1.1009\n",
      "RF: Train RMSE: 1.4908, Test RMSE: 1.0296\n",
      "Outliers shape: (24,)\n",
      "Outliers shape: (9,)\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_split=10,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 1.769167614224707\n",
      "\n",
      "Standard error: 0.7040207445092992\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat     lb_pvalue\n",
      "10  61.34265  2.017294e-09\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 148661.8030801111, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  304.734053  1.551207e-59\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 17426369.45340743, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.5524366740384892\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  12.624291   0.245443\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1650795.4684493272, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10  0.13885        1.0\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 17542780.589898814, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=10, n_neighbors=11, weights='distance')\n",
      "\n",
      "Mean error: 1.6317487907187498\n",
      "\n",
      "Standard error: 0.36938501957116215\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10      NaN        NaN\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: nan, p-value: nan\n",
      "The Jarque-Bera test suggests that the residuals are normally distributed (p-value >= 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10      NaN        NaN\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: nan, p-value: nan\n",
      "The Jarque-Bera test suggests that the residuals are normally distributed (p-value >= 0.05).\n",
      "RMSE: 1.0290804763610348\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.543887   0.673292\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 10460.297483161208, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.688504   0.143838\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1034307.7606426254, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.6517902162036218\n",
      "\n",
      "Standard error: 0.0\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  55.622548  2.415647e-08\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 7948952.488848984, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat     lb_pvalue\n",
      "10  109.3794  7.117265e-19\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 766705452.1490958, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.064588528631299\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.215623   0.607784\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11630.561568046303, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  16.79513   0.079022\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1191684.8733523672, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.5252640775069697\n",
      "\n",
      "Standard error: 0.40229665102418327\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  24.181383   0.007133\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 42245.65197281914, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  27.358404   0.002285\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 17443964.570207905, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.2059728350031853\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  15.45972   0.116178\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 291998.5344844156, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  1.167293   0.999652\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 8712052.272123396, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', min_samples_split=10,\n",
      "                      n_estimators=200, random_state=42)\n",
      "\n",
      "Mean error: 1.5218188331432445\n",
      "\n",
      "Standard error: 0.3388808391976307\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  68.400787  9.018128e-11\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 215295.99276855515, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  167.328131  9.910885e-31\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 152204917.2672929, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.3427477961747865\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  11.293313   0.335128\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1387297.6791132698, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  0.205596        1.0\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 21844323.69383476, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 1.7692, Test RMSE: 1.5524\n",
      "KNN: Train RMSE: 1.6317, Test RMSE: 1.0291\n",
      "GBR: Train RMSE: 1.6518, Test RMSE: 1.0646\n",
      "XGB: Train RMSE: 1.5253, Test RMSE: 1.2060\n",
      "RF: Train RMSE: 1.5218, Test RMSE: 1.3427\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_leaf=3,\n",
      "                      min_samples_split=10, random_state=42)\n",
      "\n",
      "Mean error: 1.4944434022846929\n",
      "\n",
      "Standard error: 0.9241470731059903\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  41.004759   0.000011\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1433992.9976583698, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat  lb_pvalue\n",
      "10  5342.01577        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 31149369293.435486, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 10.348954767246335\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.444398   0.859587\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11921.940916364349, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  15.543126   0.113479\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 814688.7757991478, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=10, n_neighbors=11)\n",
      "\n",
      "Mean error: 1.3994557336762299\n",
      "\n",
      "Standard error: 0.47857574037747824\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  40.869882   0.000012\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1086056.0980191363, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  7665.912456        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 16388966163.624355, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.840723218464511\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  3.701562   0.959807\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11653.036035498973, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  15.820853   0.104877\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 674267.5430814143, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.2569930246327456\n",
      "\n",
      "Standard error: 0.0\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  49.970559  2.702565e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1109702.1885111777, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat  lb_pvalue\n",
      "10  5615.63419        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 20285578205.851746, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.78910118661775\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  3.580517   0.964293\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 12335.331870070999, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  15.463518   0.116054\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 861167.5417321385, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.246064450636077\n",
      "\n",
      "Standard error: 0.12291699576588448\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  42.476626   0.000006\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 828840.2525427812, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  8818.359216        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 3327924311.0326843, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.939587051474271\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  4.691466   0.910813\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11990.524015423667, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  15.742548   0.107243\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 655413.9804899448, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', n_estimators=200,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 1.2702021098731924\n",
      "\n",
      "Standard error: 0.315093710717273\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  35.642412   0.000097\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 637466.3029432218, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  9127.974038        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 2214940509.6197233, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 10.064501885756082\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.174016   0.879254\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11441.065395491594, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.997844    0.13214\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 557299.8838585811, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 1.4944, Test RMSE: 10.3490\n",
      "KNN: Train RMSE: 1.3995, Test RMSE: 9.8407\n",
      "GBR: Train RMSE: 1.2570, Test RMSE: 9.7891\n",
      "XGB: Train RMSE: 1.2461, Test RMSE: 9.9396\n",
      "RF: Train RMSE: 1.2702, Test RMSE: 10.0645\n",
      "Outliers shape: (21,)\n",
      "Outliers shape: (9,)\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_leaf=10,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 1.4518158106155237\n",
      "\n",
      "Standard error: 0.8493303053629504\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  53.533038  5.927305e-08\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1280601.6020548034, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  6338.045288        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 12164543883.598866, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.999447223009344\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  3.584596   0.964148\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 15702.592225642022, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  11.188996   0.342984\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1368325.8399621276, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=10, n_neighbors=11)\n",
      "\n",
      "Mean error: 1.3984991669757993\n",
      "\n",
      "Standard error: 0.4812717665571749\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  45.704026   0.000002\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1099156.6422147104, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  7681.967198        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 16615743032.73508, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.835058981087796\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  3.732747   0.958599\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11709.662883561894, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  15.830402   0.104591\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 674463.9028165864, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.2547724593114602\n",
      "\n",
      "Standard error: 1.4901161193847656e-08\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  49.146861  3.828428e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1072242.3454860887, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  6178.369326        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 12912925618.658741, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.818076627686962\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  3.271036   0.974307\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 12088.725909462673, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  15.253117   0.123103\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 824365.1869281789, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.2461786972022102\n",
      "\n",
      "Standard error: 0.12004334314818978\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  32.503721    0.00033\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 146223.49456335718, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "         lb_stat  lb_pvalue\n",
      "10  12143.654849        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 112852333.8633669, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.900997845255091\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  4.123185   0.941619\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 10509.5078152769, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.753476       0.08\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 497568.93924374745, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', n_estimators=200,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 1.2689855876021527\n",
      "\n",
      "Standard error: 0.29695929875946\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  29.912434   0.000885\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 177879.26943959197, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "         lb_stat  lb_pvalue\n",
      "10  13315.627388        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 133218589.31339283, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.965653691738112\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  4.478989   0.923164\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11790.460809409475, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.205661   0.163816\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 616915.417593311, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 1.4518, Test RMSE: 9.9994\n",
      "KNN: Train RMSE: 1.3985, Test RMSE: 9.8351\n",
      "GBR: Train RMSE: 1.2548, Test RMSE: 9.8181\n",
      "XGB: Train RMSE: 1.2462, Test RMSE: 9.9010\n",
      "RF: Train RMSE: 1.2690, Test RMSE: 9.9657\n"
     ]
    }
   ],
   "source": [
    "#H1\n",
    "hypothesis = 'H2'\n",
    "hypothesis_results2 = {}\n",
    "# EX1\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_raw, test_raw, lags, detect_outliers=False, input_column='ts2', target_column='ts2')\n",
    "experiment = 'Raw_no_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results2[experiment] = results\n",
    "\n",
    "# EX2\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_raw, test_raw, lags, detect_outliers=True, input_column='ts2', target_column='ts2')\n",
    "experiment = 'Raw_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results2[experiment] = results\n",
    "\n",
    "# EX3\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_imp, test_raw, lags, detect_outliers=False, input_column='ts2', target_column='ts2')\n",
    "experiment = 'Imputed_no_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results2[experiment] = results\n",
    "\n",
    "# EX4 \n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_imp, test_raw, lags, detect_outliers=True, input_column='ts2', target_column='ts2')\n",
    "experiment = 'Impute_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results2[experiment] = results\n",
    "\n",
    "# Usage example:\n",
    "# plot_rmse_comparison_hypothesis(hypothesis_results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_leaf=10,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 1.9964756110606419\n",
      "\n",
      "Standard error: 1.0833794867024964\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.613585   0.146798\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 2271635.7463091537, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  169.362803  3.758634e-31\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 497516522.9349357, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.1572570438471301\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.416513   0.154827\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 10625.29022048545, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  77.497109  1.550578e-12\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1144066.5162155628, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=50, n_neighbors=11)\n",
      "\n",
      "Mean error: 1.7710531637456537\n",
      "\n",
      "Standard error: 0.7405145418058718\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  32.996843   0.000273\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 4467172.368295165, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  142.283636  1.433996e-25\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 565586266.0276381, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.0662224654003531\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  3.264558   0.974495\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 5214.335435805737, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  26.832278   0.002768\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 596924.907336413, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.6062742228122548\n",
      "\n",
      "Standard error: 0.0\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.166978   0.165511\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 4618746.6158027705, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  158.090312  8.029107e-29\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 615839548.3432871, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.1294810232431394\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.067909   0.097705\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 3886.5141935593674, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  18.923974   0.041239\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 443522.6199136722, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.6531613676556522\n",
      "\n",
      "Standard error: 0.7777353067268127\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  26.552677   0.003064\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1377780.8914524012, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  275.841675  1.962167e-53\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 263692833.80568773, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.1307216043822141\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  20.528276   0.024634\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 139654.20157364928, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  47.416898  7.928808e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11722083.005689774, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', min_samples_split=10,\n",
      "                      n_estimators=10, random_state=42)\n",
      "\n",
      "Mean error: 1.7144375514884762\n",
      "\n",
      "Standard error: 0.47349652583448026\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  15.53901   0.113611\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 5455727.198758816, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat     lb_pvalue\n",
      "10  54.25495  4.349520e-08\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 758100547.544001, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.1000384385788413\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.240004   0.162323\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 15876.649278023067, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  74.772251  5.268968e-12\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 599752.2258431752, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 1.9965, Test RMSE: 1.1573\n",
      "KNN: Train RMSE: 1.7711, Test RMSE: 1.0662\n",
      "GBR: Train RMSE: 1.6063, Test RMSE: 1.1295\n",
      "XGB: Train RMSE: 1.6532, Test RMSE: 1.1307\n",
      "RF: Train RMSE: 1.7144, Test RMSE: 1.1000\n",
      "Outliers shape: (17,)\n",
      "Outliers shape: (3,)\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_leaf=10,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 2.2140140305698073\n",
      "\n",
      "Standard error: 1.6886883705276645\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.613585   0.146798\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 2271635.7463091537, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  169.362803  3.758634e-31\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 497516522.9349357, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.1572570438471301\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.416513   0.154827\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 10625.290220485458, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  77.497109  1.550578e-12\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1144066.5162155628, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=50, n_neighbors=11)\n",
      "\n",
      "Mean error: 1.77055666163571\n",
      "\n",
      "Standard error: 0.7409306366034807\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10  33.0146   0.000271\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 4467207.800990269, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  142.283661  1.433979e-25\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 565586202.1435921, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.0662224654003531\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  3.264558   0.974495\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 5214.335435805737, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  26.832278   0.002768\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 596924.907336413, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.6062742228122548\n",
      "\n",
      "Standard error: 0.0\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.166978   0.165511\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 4618746.6158027705, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  158.090312  8.029107e-29\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 615839548.3432871, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.1294810232431394\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.067909   0.097705\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 3886.5141935593674, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  18.923974   0.041239\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 443522.6199136722, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.6531884628332176\n",
      "\n",
      "Standard error: 0.7777602723780283\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  26.552677   0.003064\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1377780.8914524012, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  275.841675  1.962167e-53\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 263692833.80568773, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.1307216043822141\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  20.528276   0.024634\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 139654.20157364928, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  47.416898  7.928808e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11722083.005689774, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', min_samples_split=10,\n",
      "                      n_estimators=50, random_state=42)\n",
      "\n",
      "Mean error: 1.7346909131310337\n",
      "\n",
      "Standard error: 0.5909931955583869\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.030532   0.098762\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 3101475.858072506, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  82.308877  1.768185e-13\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 631819236.7784127, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.0798736020747963\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.713211   0.080956\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 24600.368728723588, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  88.999151  8.456538e-15\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 2183440.438044688, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 2.2140, Test RMSE: 1.1573\n",
      "KNN: Train RMSE: 1.7706, Test RMSE: 1.0662\n",
      "GBR: Train RMSE: 1.6063, Test RMSE: 1.1295\n",
      "XGB: Train RMSE: 1.6532, Test RMSE: 1.1307\n",
      "RF: Train RMSE: 1.7347, Test RMSE: 1.0799\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_split=10,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 1.4743348833581187\n",
      "\n",
      "Standard error: 0.871067594854819\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  66.523078  2.070219e-10\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1635307.3651387745, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  6174.928798        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 23967539919.259293, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.905448406933258\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.026643   0.889391\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 10236.05733986322, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  13.122691   0.216893\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 597781.8882419973, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=50, n_neighbors=11)\n",
      "\n",
      "Mean error: 1.3810793775654586\n",
      "\n",
      "Standard error: 0.4220659291352188\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  51.478629  1.424835e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1224032.4136850943, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  6757.130335        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 20103323657.234642, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.786128586543851\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  3.917191   0.951005\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11517.822578759977, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.870318   0.077283\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 638608.258435505, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.2486209183130854\n",
      "\n",
      "Standard error: 0.0\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  85.738648  3.731776e-14\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 920135.2771653865, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  7362.705964        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 12529146849.459303, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.783823252680802\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  4.250738   0.935328\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11661.244480288988, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.371131    0.08949\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 603598.2101184735, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.2475705207803056\n",
      "\n",
      "Standard error: 0.10856071151067091\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  55.786726  2.250641e-08\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1265758.451609442, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  7403.501098        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 14583781146.889406, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.755132835417257\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  4.368905   0.929174\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11638.50047931271, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  15.974071   0.100377\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 621668.9023979484, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', n_estimators=10,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 1.2698981402928597\n",
      "\n",
      "Standard error: 0.32193988162841813\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat     lb_pvalue\n",
      "10  58.61462  6.621121e-09\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 706095.6807295145, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  8103.248257        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 6524658039.136938, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.776991282804048\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  4.086717    0.94335\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11549.983730853628, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  15.887632   0.102895\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 625393.3474536149, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 1.4743, Test RMSE: 9.9054\n",
      "KNN: Train RMSE: 1.3811, Test RMSE: 9.7861\n",
      "GBR: Train RMSE: 1.2486, Test RMSE: 9.7838\n",
      "XGB: Train RMSE: 1.2476, Test RMSE: 9.7551\n",
      "RF: Train RMSE: 1.2699, Test RMSE: 9.7770\n",
      "Outliers shape: (12,)\n",
      "Outliers shape: (3,)\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_leaf=5,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 1.622375925200154\n",
      "\n",
      "Standard error: 1.1264796049741945\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  54.676904  3.628646e-08\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1603454.080998812, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  6370.598821        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 23541324091.95392, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.823006494213308\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.097396   0.884578\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 10871.375682715825, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.154485   0.095295\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 619025.0781582441, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=50, n_neighbors=11)\n",
      "\n",
      "Mean error: 1.3810197658745318\n",
      "\n",
      "Standard error: 0.42196499846882607\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  51.128306  1.653753e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1224041.6271843507, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  6754.004961        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 20114564349.05976, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.786128586543851\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  3.917191   0.951005\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11517.822578759977, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.870318   0.077283\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 638608.258435505, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.2486209183130854\n",
      "\n",
      "Standard error: 0.0\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  85.738648  3.731776e-14\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 920135.2771653865, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  7362.705964        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 12529146849.459303, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.783823252680802\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  4.250738   0.935328\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11661.244480288988, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.371131    0.08949\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 603598.2101184735, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.2476447671996023\n",
      "\n",
      "Standard error: 0.11075887149746964\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  57.809588  9.388527e-09\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1295805.819688306, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat  lb_pvalue\n",
      "10  7303.37161        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 15264536496.393105, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.752969151102196\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  4.556859   0.918751\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11734.427362871018, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  15.681523   0.109119\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 622168.0822825556, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=20, max_features='auto', n_estimators=200,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 1.270961366451122\n",
      "\n",
      "Standard error: 0.3288061174057045\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  85.490851  4.176562e-14\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 183182.51616118074, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "10  8724.861629        0.0\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 508210200.31586707, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 9.76384732116796\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  4.519872   0.920863\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11694.734997350452, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  15.720751    0.10791\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 614624.4673836137, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 1.6224, Test RMSE: 9.8230\n",
      "KNN: Train RMSE: 1.3810, Test RMSE: 9.7861\n",
      "GBR: Train RMSE: 1.2486, Test RMSE: 9.7838\n",
      "XGB: Train RMSE: 1.2476, Test RMSE: 9.7530\n",
      "RF: Train RMSE: 1.2710, Test RMSE: 9.7638\n"
     ]
    }
   ],
   "source": [
    "#H1\n",
    "hypothesis = 'H3'\n",
    "hypothesis_results3 = {}\n",
    "# EX1\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_raw, test_raw, lags, detect_outliers=False, input_column='ts1', target_column='ts2')\n",
    "experiment = 'Raw_no_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results3[experiment] = results\n",
    "\n",
    "# EX2\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_raw, test_raw, lags, detect_outliers=True, input_column='ts1', target_column='ts2')\n",
    "experiment = 'Raw_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results3[experiment] = results\n",
    "\n",
    "# EX3\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_imp, test_raw, lags, detect_outliers=False, input_column='ts1', target_column='ts2')\n",
    "experiment = 'Imputed_no_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results3[experiment] = results\n",
    "\n",
    "# EX4 \n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_imp, test_raw, lags, detect_outliers=True, input_column='ts1', target_column='ts2')\n",
    "experiment = 'Impute_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results3[experiment] = results\n",
    "\n",
    "# Usage example:\n",
    "# plot_rmse_comparison_hypothesis(hypothesis_results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_leaf=3,\n",
      "                      min_samples_split=10, random_state=42)\n",
      "\n",
      "Mean error: 2.080851891153144\n",
      "\n",
      "Standard error: 0.7824304105201031\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  29.387601   0.001078\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 45773.291286826905, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  25.767485   0.004066\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 35204974.77307855, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.436474025534981\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  11.320673   0.333086\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 20435.94768248713, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.444677   0.682903\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1711646.9241053557, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=10, n_neighbors=11)\n",
      "\n",
      "Mean error: 1.9416795209684237\n",
      "\n",
      "Standard error: 0.4889066050644144\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  46.211266   0.000001\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 54465.223809406874, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  87.425015  1.732788e-14\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 19012581.377106, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.4505999897278157\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.088151   0.097137\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 16476.426550258253, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.086883   0.885299\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1507611.7669881014, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.914151101997111\n",
      "\n",
      "Standard error: 2.1073424255447017e-08\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  40.266527   0.000015\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 53593.8599494782, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  29.677766   0.000967\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 24441853.698254067, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.5016671435332651\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  11.333265    0.33215\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 15210.617786124865, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.062077   0.810021\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1708008.0444516554, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.889775742570669\n",
      "\n",
      "Standard error: 0.1666948496678047\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  37.304092    0.00005\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 46247.779646940464, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  21.695204   0.016735\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 51862013.91201784, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.4424158665134543\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.955819   0.536302\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 20082.191641058165, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.564724    0.67127\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1657633.0449197262, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', min_samples_split=10,\n",
      "                      n_estimators=50, random_state=42)\n",
      "\n",
      "Mean error: 1.8952729367835275\n",
      "\n",
      "Standard error: 0.2990777086393841\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  35.402289   0.000107\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 28508.024906431874, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  45.571677   0.000002\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 24923780.220197607, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.4329614429317896\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  11.823275   0.297058\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 21378.318653833718, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.491961   0.678326\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1738744.4142175016, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 2.0809, Test RMSE: 1.4365\n",
      "KNN: Train RMSE: 1.9417, Test RMSE: 1.4506\n",
      "GBR: Train RMSE: 1.9142, Test RMSE: 1.5017\n",
      "XGB: Train RMSE: 1.8898, Test RMSE: 1.4424\n",
      "RF: Train RMSE: 1.8953, Test RMSE: 1.4330\n",
      "Outliers shape: (24,)\n",
      "Outliers shape: (9,)\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', min_samples_leaf=3,\n",
      "                      min_samples_split=10, random_state=42)\n",
      "\n",
      "Mean error: 2.076110571165266\n",
      "\n",
      "Standard error: 0.754479729299339\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  29.387601   0.001078\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 45773.291286826905, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  25.767485   0.004066\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 35204974.77307855, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.436474025534981\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  11.320673   0.333086\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 20435.94768248713, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.444677   0.682903\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1711646.9241053557, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=10, n_neighbors=11)\n",
      "\n",
      "Mean error: 1.9413333066771747\n",
      "\n",
      "Standard error: 0.48927958610738304\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  46.225335   0.000001\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 54463.87116020616, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat     lb_pvalue\n",
      "10  87.40119  1.751687e-14\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 19010710.82144231, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.4505999897278157\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  16.088151   0.097137\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 16476.426550258253, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.086883   0.885299\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1507611.7669881014, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 1.914151101997111\n",
      "\n",
      "Standard error: 2.1073424255447017e-08\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  40.266527   0.000015\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 53593.8599494782, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  29.677766   0.000967\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 24441853.698254067, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.5016671435332651\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  11.333265    0.33215\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 15210.617786124865, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.062077   0.810021\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1708008.0444516554, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 1.8897657295692893\n",
      "\n",
      "Standard error: 0.1735927124404077\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  39.059954   0.000025\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 40696.94524554877, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  28.186553   0.001685\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 49536414.74883513, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.443434484545219\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  9.727472    0.46472\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 20141.317117763443, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat  lb_pvalue\n",
      "10  7.58356   0.669441\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1663986.11033679, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', n_estimators=10,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 1.8858478049349447\n",
      "\n",
      "Standard error: 0.25617140790742693\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  37.728551   0.000042\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 38546.667879051194, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  21.361602   0.018709\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 62548143.72162997, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 1.4349369747210252\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  11.478828   0.321448\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 20909.065365556446, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.733418   0.654858\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1710016.6258599188, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 2.0761, Test RMSE: 1.4365\n",
      "KNN: Train RMSE: 1.9413, Test RMSE: 1.4506\n",
      "GBR: Train RMSE: 1.9142, Test RMSE: 1.5017\n",
      "XGB: Train RMSE: 1.8898, Test RMSE: 1.4434\n",
      "RF: Train RMSE: 1.8858, Test RMSE: 1.4349\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', random_state=42)\n",
      "\n",
      "Mean error: 11.754296391316444\n",
      "\n",
      "Standard error: 7.584809742851267\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  51.949394  1.165995e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 56901769.71426139, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  176.961884  1.000591e-32\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 298813358079.89075, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 68.48854135389773\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  13.48594   0.197756\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 36187.37069034669, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.011847   0.890385\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 4345869.402090846, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=10, n_neighbors=9)\n",
      "\n",
      "Mean error: 10.17574342121367\n",
      "\n",
      "Standard error: 4.101015332376467\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  43.646122   0.000004\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 117290697.51022606, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat     lb_pvalue\n",
      "10  99.29609  7.537188e-17\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 720671819039.7404, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.73612547521851\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  11.556049   0.315866\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 22420.63629134974, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.445834   0.682791\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1867138.3393472997, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 8.624842049841165\n",
      "\n",
      "Standard error: 1.1920928955078125e-07\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  54.391659  4.101616e-08\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 73664520.97666457, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  105.432788  4.433044e-18\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 522398639465.304, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.48263920612203\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  12.195914   0.272159\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 21980.14671019892, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.779303   0.650384\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1770224.3580246894, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 8.547440074913778\n",
      "\n",
      "Standard error: 0.9851728706099019\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  52.072801  1.106244e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 15810622.012112664, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "    lb_stat     lb_pvalue\n",
      "10  407.774  2.084058e-81\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 82024574657.4674, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.79014353367987\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  12.759063   0.237457\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 25819.93861911263, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.868056   0.826224\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 2801803.825813289, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', min_samples_split=5,\n",
      "                      n_estimators=200, random_state=42)\n",
      "\n",
      "Mean error: 8.822140947584991\n",
      "\n",
      "Standard error: 2.316561709459977\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  53.889718  5.087229e-08\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11735160.093808562, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat      lb_pvalue\n",
      "10  549.931382  9.271739e-112\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 68695277758.44458, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.50564569769317\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  12.801967   0.234956\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 22157.729971589193, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  6.850575   0.739472\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 2072273.7029738124, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 11.7543, Test RMSE: 68.4885\n",
      "KNN: Train RMSE: 10.1757, Test RMSE: 64.7361\n",
      "GBR: Train RMSE: 8.6248, Test RMSE: 64.4826\n",
      "XGB: Train RMSE: 8.5474, Test RMSE: 64.7901\n",
      "RF: Train RMSE: 8.8221, Test RMSE: 64.5056\n",
      "Outliers shape: (21,)\n",
      "Outliers shape: (9,)\n",
      "\n",
      "Training CART model...\n",
      "Fitting 30 folds for each of 60 candidates, totalling 1800 fits\n",
      "\n",
      "Best model: DecisionTreeRegressor(max_depth=10, max_features='auto', random_state=42)\n",
      "\n",
      "Mean error: 11.538360249969637\n",
      "\n",
      "Standard error: 7.866973399887064\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  51.949394  1.165995e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 56901769.714261286, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  176.961884  1.000591e-32\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 298813358079.89075, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 67.29443281350035\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  14.346757   0.157754\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 38494.038134982766, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.164686   0.879909\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 5138768.677325511, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training KNN model...\n",
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "\n",
      "Best model: KNeighborsRegressor(leaf_size=10, n_neighbors=9)\n",
      "\n",
      "Mean error: 10.175346187832545\n",
      "\n",
      "Standard error: 4.101246645899322\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  42.599496   0.000006\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 112385057.64343168, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  101.795434  2.381090e-17\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 702697953560.882, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.73519672803997\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  11.55468   0.315965\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 22424.223159346213, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.446751   0.682702\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1867131.2669544213, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training GBR model...\n",
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__n_estimators\n",
      "[LightGBM] [Warning] Unknown parameter: lgbmregressor__num_leaves\n",
      "\n",
      "Best model: LGBMRegressor(lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=5,\n",
      "              lgbmregressor__n_estimators=100, lgbmregressor__num_leaves=35,\n",
      "              random_state=42)\n",
      "\n",
      "Mean error: 8.700667027244457\n",
      "\n",
      "Standard error: 0.0\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  56.258902  1.835937e-08\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 70396667.17900588, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  105.513769  4.269969e-18\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 481832408968.9078, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.64526742771015\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  12.119098   0.277165\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 22020.410438932442, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  8.407615   0.589087\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 1788643.3385364695, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training XGB model...\n",
      "Fitting 30 folds for each of 18 candidates, totalling 540 fits\n",
      "\n",
      "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "\n",
      "Mean error: 8.537271907400635\n",
      "\n",
      "Standard error: 0.8849246442633939\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  51.928157  1.176596e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 11118670.603110941, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  489.484832  7.788822e-99\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 55602603523.05261, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.99174067554785\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  13.137961    0.21606\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 28018.254158791537, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  5.391066   0.863572\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 3117903.047052613, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Training RF model...\n",
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10, max_features='auto', min_samples_split=5,\n",
      "                      random_state=42)\n",
      "\n",
      "Mean error: 8.812350324536828\n",
      "\n",
      "Standard error: 2.35410054470915\n",
      "\n",
      "Residual analysis for train set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat     lb_pvalue\n",
      "10  51.730976  1.279704e-07\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 9917350.02243513, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "       lb_stat      lb_pvalue\n",
      "10  574.983914  4.019615e-117\n",
      "The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 44180114119.070114, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "RMSE: 64.54852142304159\n",
      "\n",
      "Residual analysis for test set:\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  13.013746   0.222904\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 21817.121039730086, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Residuals squared\n",
      "\n",
      "Homoscedasticity scatter plot:\n",
      "Ljung-Box test for autocorrelation in residuals:\n",
      "     lb_stat  lb_pvalue\n",
      "10  7.061413   0.719635\n",
      "The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\n",
      "\n",
      "Jarque-Bera test for normality in residuals:\n",
      "Test statistic: 2069031.5623063042, p-value: 0.0\n",
      "The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\n",
      "\n",
      "Results:\n",
      "CART: Train RMSE: 11.5384, Test RMSE: 67.2944\n",
      "KNN: Train RMSE: 10.1753, Test RMSE: 64.7352\n",
      "GBR: Train RMSE: 8.7007, Test RMSE: 64.6453\n",
      "XGB: Train RMSE: 8.5373, Test RMSE: 64.9917\n",
      "RF: Train RMSE: 8.8124, Test RMSE: 64.5485\n"
     ]
    }
   ],
   "source": [
    "#H1\n",
    "hypothesis = 'H4'\n",
    "hypothesis_results4 = {}\n",
    "# EX1\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_raw, test_raw, lags, detect_outliers=False, input_column='ts2', target_column='ts1')\n",
    "experiment = 'Raw_no_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results4[experiment] = results\n",
    "\n",
    "# EX2\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_raw, test_raw, lags, detect_outliers=True, input_column='ts2', target_column='ts1')\n",
    "experiment = 'Raw_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results4[experiment] = results\n",
    "\n",
    "# EX3\n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_imp, test_raw, lags, detect_outliers=False, input_column='ts2', target_column='ts1')\n",
    "experiment = 'Imputed_no_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results4[experiment] = results\n",
    "\n",
    "# EX4 \n",
    "X_train, Y_train, X_test, Y_test,scaler_X, scaler_Y = process_data(train_imp, test_raw, lags, detect_outliers=True, input_column='ts2', target_column='ts1')\n",
    "experiment = 'Impute_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results4[experiment] = results\n",
    "\n",
    "# Usage example:\n",
    "# plot_rmse_comparison_hypothesis(hypothesis_results4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_raw_data(\"Test_data.csv\")\n",
    "raw_hourly = df.resample('D').mean()\n",
    "raw_ts_1_daily = raw_hourly['ts1'].dropna()\n",
    "raw_ts_2_daily = raw_hourly['ts2'].dropna()\n",
    "# Run the Monte Carlo simulation on your time series data\n",
    "print('Univariate')\n",
    "average_results = monte_carlo_simulation(raw_ts_1_daily, n_trials=1000)\n",
    "print(average_results)\n",
    "average_results = monte_carlo_simulation(raw_ts_2_daily, n_trials=1000)\n",
    "print(average_results)\n",
    "print('Multivariate')\n",
    "# Run the Monte Carlo simulation on your time series data\n",
    "average_results = monte_carlo_simulation_mult(raw_ts_1_daily, raw_ts_2_daily)\n",
    "print(average_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 1 Raw NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test\n",
    "# train_data, test_data = train_test_split(raw_rt_daily, test_size=0.2, shuffle=False)\n",
    "train_data, test_data = raw_rt_daily.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts1', lags)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts1', lags)\n",
    "train_transformed = train_transformed.drop(['ts2'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts2'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts1')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts1')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts1')\n",
    "\n",
    "\n",
    "hypothesis = 'H1'\n",
    "experiment = 'Raw_no_outliers'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test\n",
    "train_data, test_data = raw_rt_daily.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts2', lags)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts2', lags)\n",
    "train_transformed = train_transformed.drop(['ts1'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts1'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts2')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts2')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts2')\n",
    "\n",
    "hypothesis = 'H2'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Raw_no_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test\n",
    "train_data, test_data = raw_rt_daily.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts1', lags)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts1', lags)\n",
    "train_transformed = train_transformed.drop(['ts1'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts1'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts2')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts2')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts2')\n",
    "\n",
    "\n",
    "hypothesis = 'H3'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Raw_no_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test\n",
    "train_data, test_data = raw_rt_daily.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts2', lags)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts2', lags)\n",
    "train_transformed = train_transformed.drop(['ts2'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts2'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts1')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts1')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts1')\n",
    "\n",
    "\n",
    "hypothesis = 'H4'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Raw_no_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 2 Raw WO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_1 = train_data['ts1']\n",
    "squared_rt2 = rt_1.pow(2).dropna()\n",
    "\n",
    "# Perform cluster-based outlier detection for both series\n",
    "outliers_rt1 = cluster_based_outlier_detection(squared_rt2)\n",
    "outliers_rt1[outliers_rt1['outliers'] == 1]\n",
    "\n",
    "# Plot the original series rt_1\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(rt_1, label='rt_1')\n",
    "\n",
    "# Get the indices and values of the outliers\n",
    "outlier_indices = outliers_rt1[outliers_rt1['outliers'] == 1].index\n",
    "outlier_values = rt_1.loc[outlier_indices]\n",
    "\n",
    "# Plot the outliers as red dots\n",
    "plt.scatter(outlier_indices, outlier_values, color='red', label='Outliers')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Return')\n",
    "plt.title('Return Series with Outliers')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Split train/test\n",
    "# train_data, test_data = train_test_split(raw_rt_daily, test_size=0.2, shuffle=False)\n",
    "train_data, test_data = raw_rt_daily.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts1', lags, detect_outliers=True)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts1', lags, detect_outliers=True)\n",
    "# train_transformed = prepare_time_series_data(train_data, 'ts1_raw', lags)\n",
    "# test_transformed = prepare_time_series_data(test_data, 'ts1_raw', lags)\n",
    "train_transformed = train_transformed.drop(['ts2'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts2'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts1')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts1')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts1')\n",
    "\n",
    "hypothesis = 'H1'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Raw_outliers'\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test\n",
    "train_data, test_data = raw_rt_daily.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts2', lags, detect_outliers=True)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts2', lags, detect_outliers=True)\n",
    "train_transformed = train_transformed.drop(['ts1'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts1'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts2')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts2')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts2')\n",
    "\n",
    "hypothesis = 'H2'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Raw_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test\n",
    "train_data, test_data = raw_rt_daily.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts1', lags, detect_outliers=True)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts1', lags, detect_outliers=True)\n",
    "train_transformed = train_transformed.drop(['ts1'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts1'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts2')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts2')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts2')\n",
    "\n",
    "\n",
    "hypothesis = 'H3'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Raw_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test\n",
    "train_data, test_data = raw_rt_daily.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts2', lags, detect_outliers=True)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts2', lags, detect_outliers=True)\n",
    "train_transformed = train_transformed.drop(['ts2'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts2'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts1')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts1')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts1')\n",
    "\n",
    "\n",
    "hypothesis = 'H4'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Raw_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 3 Imp NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test rt_d.iloc[:int(len(raw_rt_daily)*0.8), :]\n",
    "train_data, test_data = rt_d.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts1', lags)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts1', lags)\n",
    "train_transformed = train_transformed.drop(['ts2'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts2'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts1')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts1')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts1')\n",
    "\n",
    "\n",
    "hypothesis = 'H1'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Imputed_no_outliers'\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test\n",
    "train_data, test_data = rt_d.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts2', lags)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts2', lags)\n",
    "train_transformed = train_transformed.drop(['ts1'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts1'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts2')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts2')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts2')\n",
    "\n",
    "hypothesis = 'H2'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Imputed_no_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test\n",
    "train_data, test_data = rt_d.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts1', lags)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts1', lags)\n",
    "train_transformed = train_transformed.drop(['ts1'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts1'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts2')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts2')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts2')\n",
    "\n",
    "\n",
    "hypothesis = 'H3'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Imputed_no_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test\n",
    "train_data, test_data = rt_d.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts2', lags)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts2', lags)\n",
    "train_transformed = train_transformed.drop(['ts2'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts2'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts1')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts1')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts1')\n",
    "\n",
    "\n",
    "hypothesis = 'H4'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Imputed_no_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 4 Imputed WO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test rt_d.iloc[:int(len(raw_rt_daily)*0.8), :]\n",
    "train_data, test_data = rt_d.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts1', lags, detect_outliers=True)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts1', lags, detect_outliers=True)\n",
    "train_transformed = train_transformed.drop(['ts2'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts2'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts1')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts1')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts1')\n",
    "\n",
    "\n",
    "hypothesis = 'H1'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Impute_outliers'\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test rt_d.iloc[:int(len(raw_rt_daily)*0.8), :]\n",
    "train_data, test_data = rt_d.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts2', lags, detect_outliers=True)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts2', lags, detect_outliers=True)\n",
    "train_transformed = train_transformed.drop(['ts1'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts1'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts2')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts2')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts2')\n",
    "\n",
    "hypothesis = 'H2'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Impute_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test rt_d.iloc[:int(len(raw_rt_daily)*0.8), :]\n",
    "train_data, test_data = rt_d.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts1', lags, detect_outliers=True)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts1', lags, detect_outliers=True)\n",
    "train_transformed = train_transformed.drop(['ts1'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts1'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts2')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts2')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts2')\n",
    "\n",
    "\n",
    "hypothesis = 'H3'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Impute_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test rt_d.iloc[:int(len(raw_rt_daily)*0.8), :]\n",
    "train_data, test_data = rt_d.iloc[:int(len(raw_rt_daily)*0.8), :], raw_rt_daily.iloc[int(len(raw_rt_daily)*0.8):, :]\n",
    "#set up data for supervised learning for H1: ts1 pred ts1\n",
    "train_transformed = prepare_time_series_data(train_data, 'ts2', lags, detect_outliers=True)\n",
    "test_transformed = prepare_time_series_data(test_data, 'ts2', lags, detect_outliers=True)\n",
    "train_transformed = train_transformed.drop(['ts2'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ts2'], axis=1)\n",
    "# 2. Scale based on train set\n",
    "train_data_scaled, test_data_scaled, scaler_X, scaler_Y = scale_data(train_transformed, test_transformed, 'ts1')\n",
    "# 3. Create supervised learning data by adding datetime features and lagged features\n",
    "train_data_df = pd.DataFrame(train_data_scaled, index=train_transformed.index, columns=train_transformed.columns)\n",
    "test_data_df = pd.DataFrame(test_data_scaled, index=test_transformed.index, columns=test_transformed.columns)\n",
    "X_train, Y_train = extract_column(train_data_df, 'ts1')\n",
    "X_test, Y_test = extract_column(test_data_df, 'ts1')\n",
    "\n",
    "\n",
    "hypothesis = 'H4'+\"_split_\"+str(n_splits)+\"_test_size_\"+str(test_size)\n",
    "experiment = 'Impute_outliers'\n",
    "\n",
    "results = {}\n",
    "\n",
    "results = run_experiment(models_and_param_grids, X_train, Y_train, X_test, Y_test, tscv, scaler_Y, hypothesis, experiment)\n",
    "hypothesis_results[experiment+hypothesis] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import data\n",
    "- Apply imputation and cleaning methods\n",
    "- Transform to returns\n",
    "- Resample\n",
    "- Split training and holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into function\n",
    "filename = \"Test_data.csv\"\n",
    "raw_df = pd.read_csv(filename, header=None)\n",
    "raw_df.columns = ['datetime', 'ts1', 'ts2']\n",
    "raw_df['datetime'] = pd.to_datetime(raw_df['datetime']-719529,unit='d').round('s')\n",
    "raw_df.set_index('datetime', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(ts1, ts2, ts1_label='ts1', ts2_label='ts2', figsize=(12, 10)):\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=1, figsize=figsize)\n",
    "\n",
    "    # Plot first time series on first subplot\n",
    "    axs[0].plot(ts1)\n",
    "    axs[0].set_xlabel('Date')\n",
    "    axs[0].set_ylabel('Price')\n",
    "    axs[0].set_title(ts1_label)\n",
    "\n",
    "    # Plot second time series on second subplot\n",
    "    axs[1].plot(ts2)\n",
    "    axs[1].set_xlabel('Date')\n",
    "    axs[1].set_ylabel('Price')\n",
    "    axs[1].set_title(ts2_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count missing values in a series\n",
    "def count_missing_values(series):\n",
    "    return series.isna().sum()\n",
    "\n",
    "# Function to find the maximum length of continuous missing values in a series\n",
    "def max_missing_range(series):\n",
    "    mask = series.isna()\n",
    "    changes = mask.ne(mask.shift()).cumsum()\n",
    "    counts = mask.groupby(changes).sum()\n",
    "    counts = counts[counts > 1]\n",
    "    if counts.empty:\n",
    "        return 0\n",
    "    else:\n",
    "        return counts.max()\n",
    "\n",
    "# Function to impute missing values in a series using a moving mean\n",
    "def impute_missing_values(series, window):\n",
    "    if series.isnull().any():\n",
    "        rolling_mean = series.rolling(window=window, min_periods=1).mean()\n",
    "        return series.fillna(rolling_mean)\n",
    "    else:\n",
    "        return series\n",
    "\n",
    "# Function to convert intervals to days\n",
    "def intervals_to_days(intervals):\n",
    "    minutes = intervals * 2\n",
    "    hours = minutes / 60\n",
    "    days = hours / 24\n",
    "    return days\n",
    "\n",
    "def rolling_mean(series, window=120):\n",
    "    if series.isnull().any():\n",
    "        # Create a copy of the series\n",
    "        imputed_series = series.copy()\n",
    "        \n",
    "        # Identify the non-missing blocks of data\n",
    "        non_missing_blocks = series.notna().astype(int).groupby(series.isna().astype(int).cumsum()).cumsum()\n",
    "\n",
    "        # Loop through the non-missing blocks and calculate the rolling mean for each block\n",
    "        for _, block in non_missing_blocks.groupby(non_missing_blocks):\n",
    "            start_idx = block.index[0]\n",
    "            end_idx = block.index[-1] + pd.Timedelta(minutes=2)  # Change this line to fix the error\n",
    "            rolling_mean_block = series[start_idx:end_idx].rolling(window=window, min_periods=1).mean()\n",
    "            imputed_series[start_idx:end_idx] = series[start_idx:end_idx].fillna(rolling_mean_block)\n",
    "        \n",
    "        imputed_series.fillna(method='bfill', inplace=True)  # Backfill since missing starting data\n",
    "    else:\n",
    "        imputed_series = series\n",
    "    return imputed_series\n",
    "\n",
    "\n",
    "def impute_missing_values(data, short_gap_threshold=120, long_gap_threshold = 2880): #120 is 240 minutes, 2880 is 4 days\n",
    "\n",
    "    # Identify the missing value gaps\n",
    "    missing_gaps = data.isna().astype(int).groupby(data.notna().astype(int).cumsum()).cumsum()\n",
    "\n",
    "    # Apply moving mean imputation for shorter gaps\n",
    "    data_short_gaps = data.copy()\n",
    "    data_short_gaps[missing_gaps <= short_gap_threshold] = rolling_mean(data_short_gaps)\n",
    "    \n",
    "    # Apply moving mean imputation for longer gaps\n",
    "    data_long_gaps = data.copy()\n",
    "    data_long_gaps[missing_gaps > short_gap_threshold] = rolling_mean(data_long_gaps,long_gap_threshold )\n",
    "\n",
    "    # Combine the imputed data\n",
    "    data_imputed = data_short_gaps.combine_first(data_long_gaps)\n",
    "    \n",
    "    # Impute any leftover missing values using backfill and forward fill methods\n",
    "    data_imputed.fillna(method='bfill', inplace=True)  # Backfill\n",
    "    data_imputed.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "    \n",
    "    return data_imputed\n",
    "\n",
    "def fill_forward_saturdays(series):\n",
    "    # Make a copy of the series\n",
    "    filled_series = series.copy()\n",
    "    # Filter the index to include only Saturdays\n",
    "    saturday_index = series.index.weekday == 5\n",
    "    # Forward fill only on Saturdays\n",
    "    filled_series.loc[saturday_index] = filled_series.loc[saturday_index].fillna(method='ffill')\n",
    "    # Return the filled series\n",
    "    return filled_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = raw_df['ts1']\n",
    "ts2 = raw_df['ts2']\n",
    "\n",
    "# Get the maximum missing range in ts1 and ts2\n",
    "max_ts1 = max_missing_range(ts1)\n",
    "max_ts2 = max_missing_range(ts2)\n",
    "print(f\"Max missing range in ts1: {max_ts1}\")\n",
    "print(f\"Max missing range in ts2: {max_ts2}\")\n",
    "\n",
    "\n",
    "# Impute missing values in ts1 and ts2 using their respective maximum missing ranges\n",
    "imputed_ts1 = impute_missing_values(ts1,long_gap_threshold = max_ts1)\n",
    "imputed_ts2 = impute_missing_values(ts2, long_gap_threshold = max_ts2)\n",
    "\n",
    "# Print the number of missing values in the imputed series\n",
    "print(f\"Missing values in imputed ts1: {imputed_ts1.isna().sum()}\")\n",
    "print(f\"Missing values in imputed ts2: {imputed_ts2.isna().sum()}\")\n",
    "\n",
    "# Calculate the maximum missing range in the imputed series\n",
    "max_imputed_ts1 = max_missing_range(imputed_ts1)\n",
    "max_imputed_ts2 = max_missing_range(imputed_ts2)\n",
    "\n",
    "# Print the maximum missing range in the imputed series\n",
    "print(f\"Max missing range in imputed ts1: {max_imputed_ts1}\")\n",
    "print(f\"Max missing range in imputed ts2: {max_imputed_ts2}\")\n",
    "#PLot original data\n",
    "# plot_time_series(ts1, ts2)\n",
    "\n",
    "# Plot the imputed time series\n",
    "# plot_time_series(imputed_ts1, imputed_ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df =  pd.concat([imputed_ts1, imputed_ts2], axis=1)\n",
    "print(clean_df.isna().sum())\n",
    "ts_1_imp = clean_df['ts1']\n",
    "ts_2_imp = clean_df['ts2']\n",
    "\n",
    "\n",
    "rt = np.log(clean_df/clean_df.shift(1))\n",
    "rt.dropna(inplace=True)\n",
    "rt_1 = rt['ts1']\n",
    "rt_2 = rt['ts2']\n",
    "plot_time_series(rt_1, rt_2, 'rt_1', 'rt_2')\n",
    "print(rt.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('clean_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rt.to_csv('rt_c.csv', index=True)\n",
    "print((rt == 0).sum())\n",
    "rt.describe()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_holdout_validation_set(data, days=30):\n",
    "#     validation_start_date = data.index.max() - pd.DateOffset(days=days - 1)\n",
    "#     train_data = data[data.index < validation_start_date]\n",
    "#     validation_data = data[data.index >= validation_start_date]\n",
    "\n",
    "#     return train_data, validation_data\n",
    "\n",
    "def split_time_series(data, percent_train):\n",
    "    n_train = int(len(data) * percent_train)\n",
    "    train_data = data.iloc[:n_train]\n",
    "    test_data = data.iloc[n_train:]\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample to daily frequency for forecasting\n",
    "# create holdout set of last month for OOS validation\n",
    "\n",
    "clean_df_daily = clean_df.resample('D').mean()\n",
    "ts_1_D = clean_df_daily['ts1']\n",
    "ts_2_D = clean_df_daily['ts2']\n",
    "# #create holdout set of last month for OOS validation\n",
    "ts_1_D_train, ts_1_D_validation = split_time_series(ts_1_D, 0.8)\n",
    "ts_2_D_train, ts_2_D_validation = split_time_series(ts_2_D, 0.8)\n",
    "\n",
    "rt_daily = rt.resample('D').mean()\n",
    "rt_1_D = rt_daily['ts1']\n",
    "rt_2_D = rt_daily['ts2']\n",
    "#create holdout set of last month for OOS validation\n",
    "rt_1_D_train, rt_1_D_validation = split_time_series(rt_1_D, 0.8)\n",
    "rt_2_D_train, rt_2_D_validation = split_time_series(rt_2_D, 0.8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rt_daily.to_csv('rt_daily.csv', index=True)\n",
    "(rt_daily==0).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Feature engineering \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for rolling forecast origin split\n",
    "def rolling_forecast_origin_split(data, window_size):\n",
    "    # Iterate through the data using a rolling window\n",
    "    for i in range(window_size, len(data)):\n",
    "        # Split the data into training and testing sets\n",
    "        train_data = data[:i-window_size]\n",
    "        test_data = data[i-window_size:i]\n",
    "        # Yield the training and testing sets\n",
    "        yield train_data, test_data\n",
    "        \n",
    "\n",
    "def create_lagged_features(series, lag=1):\n",
    "    # Create a DataFrame from the input series\n",
    "    df = pd.DataFrame(series)\n",
    "    \n",
    "    # Create lagged features\n",
    "    for i in range(1, lag + 1):\n",
    "        df[f\"lag_{i}\"] = df.shift(i)\n",
    "    \n",
    "    # Drop rows with missing values caused by shifting\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_lagged_features(ts_data, var, max_lag):\n",
    "    for t in range(1, max_lag+1):\n",
    "        ts_data[var+'_lag'+str(t)] = ts_data[var].shift(t, freq='1D')\n",
    "    ts_data.dropna(inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate\n",
    "- b. Training\n",
    "- c. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make return the model as well\n",
    "def fit_arima(train_data, test_data):\n",
    "    # Use auto_arima to select the best ARIMA model\n",
    "    model = sm.tsa.arima.auto_arima(train_data, seasonal=False, suppress_warnings=True)\n",
    "    arima_preds = model.predict(start=len(train_data), end=len(train_data)+len(test_data)-1)\n",
    "    # Return the fitted model\n",
    "    return model, arima_preds\n",
    "\n",
    "\n",
    "# Function to fit an ARIMA model\n",
    "def fit_arima(train_data, test_data):\n",
    "    # Fit an ARIMA model to the training data\n",
    "    arima_model = ARIMA(train_data, order=(1, 0, 1)).fit(disp=0)\n",
    "    # Generate predictions for the test data using the fitted model\n",
    "    arima_preds = arima_model.predict(start=len(train_data), end=len(train_data)+len(test_data)-1)\n",
    "    return arima_preds, arima_model\n",
    "\n",
    "# Function to fit a GARCH model\n",
    "def fit_garch(train_data, test_data):\n",
    "    # Fit a GARCH model to the training data\n",
    "    garch_model = arch_model(train_data, vol='Garch', p=1, o=0, q=1).fit(disp='off')\n",
    "    # Generate predictions for the test data using the fitted model\n",
    "    garch_preds = garch_model.forecast(horizon=len(test_data)).mean.iloc[-1].values\n",
    "    return garch_preds, garch_model\n",
    "\n",
    "# Function to fit a VAR model\n",
    "def fit_var(train_data, test_data):\n",
    "    # Fit a VAR model to the training data\n",
    "    model = VAR(train_data)\n",
    "    fit_model = model.fit()\n",
    "    lag_order = results.k_ar\n",
    "    # Generate predictions for the test data using the fitted model\n",
    "    preds = fit_model.forecast(train_data.values[-lag_order:], len(test_data))\n",
    "    return preds, fit_model\n",
    "\n",
    "\n",
    "def tune_sarima(y_train, seasonal=True):\n",
    "    model = pm.auto_arima(y_train,\n",
    "                          seasonal=seasonal,\n",
    "                          stepwise=True,\n",
    "                          suppress_warnings=True,\n",
    "                          trace=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def analyze_model(model):\n",
    "    # Generate diagnostic plots for the model\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    plot_acf(model.resid, ax=ax, lags=30)\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    plot_pacf(model.resid, ax=ax, lags=30)\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    model.plot_diagnostics(ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "    # Print a summary of the model\n",
    "    print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate\n",
    "- b. Training\n",
    "- c. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(train_x, train_y, test_x, test_y):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(train_x, train_y)\n",
    "    preds = model.predict(test_x)\n",
    "    mse, mae, mape = evaluate_predictions(test_y, preds)\n",
    "\n",
    "    print(\"Random Forest\")\n",
    "    print(f\"MSE: {mse:.3f}\")\n",
    "    print(f\"MAE: {mae:.3f}\")\n",
    "    print(f\"MAPE: {mape:.3f}\")\n",
    "    \n",
    "    return mse, mae, mape\n",
    "\n",
    "def train_lightgbm(train_x, train_y, test_x, test_y):\n",
    "    # Fit LightGBM model\n",
    "    params = {'objective': 'regression'}\n",
    "    d_train = lgb.Dataset(train_x, label=train_y)\n",
    "    model = lgb.train(params, d_train)\n",
    "    preds = model.predict(test_x)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    mse, mae, mape = evaluate_predictions(test_y, preds)\n",
    "\n",
    "    print(\"LightGBM\")\n",
    "    print(f\"MSE: {mse:.3f}\")\n",
    "    print(f\"MAE: {mae:.3f}\")\n",
    "    print(f\"MAPE: {mape:.3f}\")\n",
    "    \n",
    "    return mse, mae, mape\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        data_x.append(dataset[i:(i + look_back), 0])\n",
    "        data_y.append(dataset[i + look_back, 0])\n",
    "    return np.array(data_x), np.array(data_y)\n",
    "\n",
    "def unscale_data(pred, actual):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(actual)\n",
    "    pred = scaler.inverse_transform(pred)\n",
    "    actual = scaler.inverse_trans\n",
    "    form(actual)\n",
    "    return pred, actual\n",
    "\n",
    "\n",
    "def scale_data(train_data, test_data):\n",
    "    scaler = MinMaxScaler()\n",
    "    train_scaled = scaler.fit_transform(train_data)\n",
    "    test_scaled = scaler.transform(test_data)\n",
    "    return train_scaled, test_scaled\n",
    "\n",
    "\n",
    "def fit_lstm(train_x, train_y, test_x, test_y, lstm_units=50, look_back=1, num_epochs=10, batch_size=32):\n",
    "    # Reshape input to be [samples, time steps, features]\n",
    "    train_x = train_x.reshape((train_x.shape[0], look_back, 1))\n",
    "    test_x = test_x.reshape((test_x.shape[0], look_back, 1))\n",
    "\n",
    "    # Build LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(8, input_shape=(look_back, 1), return_sequences=True))\n",
    "    model.add(LSTM(4))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mape'])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(train_x, train_y, epochs=num_epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "    # Make predictions\n",
    "    train_pred = model.predict(train_x)\n",
    "    test_pred = model.predict(test_x)\n",
    "\n",
    "    # Inverse scaling of the predictions\n",
    "    train_pred = scaler.inverse_transform(train_pred)\n",
    "    train_y = scaler.inverse_transform(train_y)\n",
    "    test_pred = scaler.inverse_transform(test_pred)\n",
    "    test_y = scaler.inverse_transform(test_y)\n",
    "\n",
    "    # Create a DataFrame of the predictions and actual values\n",
    "    train_results = pd.DataFrame({'Actual': train_y.flatten(), 'Predicted': train_pred.flatten()}, index=train_data.index[1:])\n",
    "    test_results = pd.DataFrame({'Actual': test_y.flatten(), 'Predicted': test_pred.flatten()}, index=test_data.index[1:])\n",
    "\n",
    "    # Evaluate the predictions\n",
    "    train_mse, train_mae, train_mape = evaluate_predictions(train_y, train_pred)\n",
    "    test_mse, test_mae, test_mape = evaluate_predictions(test_y, test_pred)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test loss: {loss}\")\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Train MSE: {:.3f}, Train MAE: {:.3f}, Train MAPE: {:.3f}\".format(train_mse, train_mae, train_mape))\n",
    "    print(\"Test MSE: {:.3f}, Test MAE: {:.3f}, Test MAPE: {:.3f}\".format(test_mse, test_mae, test_mape))\n",
    "\n",
    "    return pd.concat([train_results, test_results])\n",
    "\n",
    "\n",
    "\n",
    "def build_lstm_model(units=50, activation='relu', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def tune_lstm(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'units': [50, 100],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'optimizer': [Adam(learning_rate=0.001), Adam(learning_rate=0.01)]\n",
    "    }\n",
    "    model = KerasRegressor(build_fn=build_lstm_model, epochs=50, batch_size=32, verbose=0)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, scoring='neg_mean_squared_error')\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    best_params = grid_result.best_params_\n",
    "    best_lstm_model = build_lstm_model(**best_params)\n",
    "    best_lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "    print(f\"Best LSTM model with parameters {best_params}\")\n",
    "    return best_lstm_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPtimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_reg.fit(housing_prepared, housing_labels)\n",
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)\n",
    "scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "pd.Series(np.sqrt(-scores)).describe()\n",
    "#####\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel=\"linear\")\n",
    "svm_reg.fit(housing_prepared, housing_labels)\n",
    "housing_predictions = svm_reg.predict(housing_prepared)\n",
    "svm_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_rmse\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg2 = DecisionTreeRegressor(random_state=42, min_samples_leaf=10)\n",
    "tree_reg1.fit(X, y)\n",
    "tree_reg2.fit(X, y)\n",
    "\n",
    "\n",
    "#####\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "grid_search_cv.best_estimator_\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "grid_search.best_params_\n",
    "grid_search.best_estimator_\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "d. Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(y_true, y_pred):\n",
    "#     mae = mean_absolute_error(y_true, y_pred)\n",
    "#     mse = mean_squared_error(y_true, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "#     r2 = r2_score(y_true, y_pred)\n",
    "#     # msle = mean_squared_log_error(y_true, y_pred)\n",
    "\n",
    "#     return {\n",
    "#         'mae': mae,\n",
    "#         'mse': mse,\n",
    "#         'rmse': rmse,\n",
    "#         'mape': mape,\n",
    "#         'r2': r2,\n",
    "#     }\n",
    "    \n",
    "def evaluate(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    # msle = mean_squared_log_error(y_true, y_pred)\n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "    }\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_kfold_validation(model, X_train, y_train, window_size=30, n_splits=5):\n",
    "\n",
    "    cv_scores = defaultdict(list)\n",
    "    kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "        y_pred_fold = []\n",
    "        \n",
    "        for X_train_window, y_train_window, X_test_window, y_test_window in rolling_forecast_origin_split(X_train_fold, y_train_fold, window_size):\n",
    "            model.fit(X_train_window, y_train_window)\n",
    "            y_pred_window = model.predict(X_test_window)\n",
    "            y_pred_fold.extend(y_pred_window)\n",
    "\n",
    "        evaluation_result = evaluate(y_test_fold, y_pred_fold)\n",
    "\n",
    "        for metric, value in evaluation_result.items():\n",
    "            cv_scores[metric].append(value)\n",
    "\n",
    "    # Calculate the mean and standard deviation of the cross-validation scores\n",
    "    mean_std_cv_scores = {}\n",
    "    for metric, scores in cv_scores.items():\n",
    "        mean_std_cv_scores[metric] = {'mean': np.mean(scores), 'std': np.std(scores)}\n",
    "\n",
    "    return mean_std_cv_scores\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select best model: H1 H2 H3 H4 BIC \n",
    "\n",
    "Optimization of best model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Residual and diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   def residual_analysis(model, data1, data2):\n",
    "#         # perform residual analysis and return the plot and print statements\n",
    "#     residuals = model.resid\n",
    "#     fig, ax = plt.subplots(figsize=(12, 6))\n",
    "#     ax.plot(residuals)\n",
    "#     ax.axhline(y=0, color='r', linestyle='-')\n",
    "#     ax.set_xlabel('Time')\n",
    "#     ax.set_ylabel('Residuals')\n",
    "#     ax.set_title('Residual Analysis')\n",
    "#     plt.show()\n",
    "#     print('Residual Analysis:')\n",
    "#     print('Mean of residuals:', round(residuals.mean(), 4))\n",
    "#     print('Standard deviation of residuals:', round(residuals.std(), 4))\n",
    "\n",
    "def diagnostics(model, data1, data2):\n",
    "    # perform diagnostics and return the print statements\n",
    "    print('Diagnostics:')\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "#write this so that it takes the predicted values and the actual values\n",
    "  \n",
    "def residual_analysis(y_pred, y_train):\n",
    "\n",
    "    # Calculate the residuals\n",
    "    residuals = y_train - y_pred\n",
    "\n",
    "    # Plot the residuals\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(residuals)\n",
    "    ax.axhline(y=0, color='r', linestyle='-')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Residuals')\n",
    "    ax.set_title('Residual Analysis')\n",
    "    plt.show()\n",
    "    print('Residual Analysis:')\n",
    "    print('Mean of residuals:', round(residuals.mean(), 4))\n",
    "    print('Standard deviation of residuals:', round(residuals.std(), 4))\n",
    "\n",
    "    # Check for autocorrelation\n",
    "    print(\"Autocorrelation plot:\")\n",
    "    plot_acf(residuals)\n",
    "    plt.show()\n",
    "\n",
    "    # Check for normality\n",
    "    print(\"Normality Q-Q plot:\")\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "    plt.show()\n",
    "\n",
    "    # Check for homoscedasticity\n",
    "    print(\"Homoscedasticity scatter plot:\")\n",
    "    plt.scatter(y_pred, residuals)\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "    plt.show()\n",
    "\n",
    "    # Perform Ljung-Box test for autocorrelation in residuals\n",
    "    lb_test = acorr_ljungbox(residuals, lags=[10], return_df=True)  \n",
    "    print(\"Ljung-Box test for autocorrelation in residuals:\")\n",
    "    print(lb_test)\n",
    "    # Assess the p-value of the Ljung-Box test\n",
    "    p_value = lb_test['lb_pvalue'][10]\n",
    "    if p_value < 0.05:\n",
    "        print(\"The Ljung-Box test suggests that there is autocorrelation in the residuals (p-value < 0.05).\")\n",
    "    else:\n",
    "        print(\"The Ljung-Box test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\")\n",
    "        \n",
    "    # Perform Breusch-Godfrey test for autocorrelation in residuals\n",
    "    bg_test = acorr_breusch_godfrey(model, X_train, nlags=10)\n",
    "    print(\"\\nBreusch-Godfrey test for autocorrelation in residuals:\")\n",
    "    if bg_test[1] < 0.05:\n",
    "        print(f\"LM test statistic: {bg_test[0]}, p-value: {bg_test[1]}\")\n",
    "        print(\"The Breusch-Godfrey test suggests that there is autocorrelation in the residuals (p-value < 0.05).\")\n",
    "    else:\n",
    "        print(f\"LM test statistic: {bg_test[0]}, p-value: {bg_test[1]}\")\n",
    "        print(\"The Breusch-Godfrey test suggests that there is no significant autocorrelation in the residuals (p-value >= 0.05).\")\n",
    "\n",
    "    # Perform Jarque-Bera test for normality in residuals\n",
    "    jb_test = jarque_bera(residuals)\n",
    "    print(\"\\nJarque-Bera test for normality in residuals:\")\n",
    "    if jb_test[1] < 0.05:\n",
    "        print(f\"Test statistic: {jb_test[0]}, p-value: {jb_test[1]}\")\n",
    "        print(\"The Jarque-Bera test suggests that the residuals are not normally distributed (p-value < 0.05).\")\n",
    "    else:\n",
    "        print(f\"Test statistic: {jb_test[0]}, p-value: {jb_test[1]}\")\n",
    "        print(\"The Jarque-Bera test suggests that the residuals are normally distributed (p-value >= 0.05).\")\n",
    "\n",
    "    # Perform White test for heteroscedasticity in residuals\n",
    "    white_test = het_white(residuals, X_train)\n",
    "    print(\"\\nWhite test for heteroscedasticity in residuals:\")\n",
    "    if white_test[1] < 0.05:\n",
    "        print(f\"Test statistic: {white_test[0]}, p-value: {white_test[1]}\")\n",
    "        print(\"The White test suggests that there is heteroscedasticity in the residuals (p-value < 0.05).\")\n",
    "    else:\n",
    "        print(f\"Test statistic: {white_test[0]}, p-value: {white_test[1]}\")\n",
    "        print(\"The White test suggests that there is no significant heteroscedasticity in the residuals (p-value >= 0.05).\")\n",
    "\n",
    "    # Perform Shapiro-Wilk test for normality in residuals\n",
    "    sw_test = shapiro(residuals)\n",
    "    print(\"\\nShapiro-Wilk test for normality in residuals:\")\n",
    "    if sw_test[1] < 0.05:\n",
    "        print(f\"Test statistic: {sw_test[0]}, p-value: {sw_test[1]}\")\n",
    "        print(\"The Shapiro-Wilk test suggests that the residuals are not normally distributed (p-value < 0.05).\")\n",
    "    else:\n",
    "        print(f\"Test statistic: {sw_test[0]}, p-value: {sw_test[1]}\")\n",
    "        print(\"The Shapiro-Wilk test suggests that the residuals are normally distributed (p-value >= 0.05).\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This function first fits the model to the provided training data and calculates the residuals. It then plots the autocorrelation, normality Q-Q plot, and homoscedasticity scatter plot. Finally, it performs the Ljung-Box test for autocorrelation in the residuals and assesses the p-value of the test.\n",
    "\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "# def residual_analysis(model, X_train, y_train):\n",
    "#     # predict on the training data\n",
    "#     y_pred = model.predict(X_train)\n",
    "\n",
    "#     # Calculate the residuals\n",
    "#     residuals = y_train - y_pred\n",
    "\n",
    "#     # Check for autocorrelation\n",
    "#     print(\"Autocorrelation plot:\")\n",
    "#     plot_acf(residuals)\n",
    "#     plt.show()\n",
    "\n",
    "#     # Check for normality\n",
    "#     print(\"Normality Q-Q plot:\")\n",
    "#     stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "#     plt.show()\n",
    "\n",
    "#     # Check for homoscedasticity\n",
    "#     print(\"Homoscedasticity scatter plot:\")\n",
    "#     plt.scatter(y_pred, residuals)\n",
    "#     plt.xlabel(\"Predicted values\")\n",
    "#     plt.ylabel(\"Residuals\")\n",
    "#     plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "#     plt.show()\n",
    "\n",
    "#     # Perform Ljung-Box test for autocorrelation in residuals\n",
    "#     lb_test = acorr_ljungbox(residuals, lags=[10], return_df=True)\n",
    "#     print(\"Ljung-Box test for autocorrelation in residuals:\")\n",
    "#     print(lb_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast and confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Save plot output from each method to file and folder "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         # Split the data into features and labels\n",
    "#         X, y = dataset_combination[0], dataset_combination[1]\n",
    "#         # Iterate through the rolling forecast origin split\n",
    "#         for X_train, y_train, X_test, y_test in rolling_forecast_origin_split(X, y, window_size=30):\n",
    "#             # Train and test the model\n",
    "#             y_pred = predict_funct(X_train, y_train, X_test)\n",
    "#             # Evaluate the model\n",
    "#             accuracy, precision, recall = evaluate_model(y_test, y_pred)\n",
    "#             # Evaluate the predictions\n",
    "#             evaluation_result = evaluate(y_pred, y_test)\n",
    "\n",
    "#             # Print the evaluation metrics\n",
    "#             print(f\"Model: {model_name}, Dataset Combination: {dataset_combination}\")\n",
    "#             print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}')\n",
    "#             print(f\"Evaluation result: {evaluation_result}\")\n",
    "\n",
    "#             # Append the evaluation results to the model_evaluations list\n",
    "#             evaluation_result.update({'model_name': model_name})\n",
    "#             model_evaluations.append(evaluation_result)\n",
    "\n",
    "#             # Train and test the model\n",
    "#             train_func(train_data)\n",
    "#             predictions = test_func(test_data)\n",
    "\n",
    "#             # Evaluate the predictions\n",
    "#             evaluation_result = evaluate(predictions, test_data)\n",
    "\n",
    "#         # Output the evaluation and CV results\n",
    "#             print(f\"Model: {model_name}, Train data: {train_data}, Test data: {test_data}\")\n",
    "#             print(f\"Evaluation result: {evaluation_result}\")\n",
    "\n",
    "#             # Append the evaluation results to the model_evaluations list\n",
    "#             evaluation_result.update({'model_name': model_name})\n",
    "#             model_evaluations.append(evaluation_result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trad\n",
    "- ARIMA\n",
    "- GARCH (depending on correlation of residuals fo ARIMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_1_imp = clean_df['ts1']\n",
    "ts_2_imp = clean_df['ts2']\n",
    "\n",
    "rt_1_D_train, rt_2_D_train\n",
    "import pandas as pd\n",
    "from pmdarima.arima import auto_arima\n",
    "from pmdarima.model_selection import cross_validate\n",
    "from pmdarima.model_selection import RollingForecastCV\n",
    "\n",
    "def plot_correlogram(x, lags=None, title=None):\n",
    "    lags = min(10, int(len(x)/5)) if lags is None else lags\n",
    "    with sns.axes_style('whitegrid'):\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 8))\n",
    "        x.plot(ax=axes[0][0], title='Residuals')\n",
    "        x.rolling(21).mean().plot(ax=axes[0][0], c='k', lw=1)\n",
    "        q_p = np.max(q_stat(acf(x, nlags=lags), len(x))[1])\n",
    "        stats = f'Q-Stat: {np.max(q_p):>8.2f}\\nADF: {adfuller(x)[1]:>11.2f}'\n",
    "        axes[0][0].text(x=.02, y=.85, s=stats, transform=axes[0][0].transAxes)\n",
    "        probplot(x, plot=axes[0][1])\n",
    "        mean, var, skew, kurtosis = moment(x, moment=[1, 2, 3, 4])\n",
    "        s = f'Mean: {mean:>12.2f}\\nSD: {np.sqrt(var):>16.2f}\\nSkew: {skew:12.2f}\\nKurtosis:{kurtosis:9.2f}'\n",
    "        axes[0][1].text(x=.02, y=.75, s=s, transform=axes[0][1].transAxes)\n",
    "        plot_acf(x=x, lags=lags, zero=False, ax=axes[1][0])\n",
    "        plot_pacf(x, lags=lags, zero=False, ax=axes[1][1])\n",
    "        axes[1][0].set_xlabel('Lag')\n",
    "        axes[1][1].set_xlabel('Lag')\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "        sns.despine()\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train test\n",
    "with train:\n",
    "    rolling cv with grid search to find best params\n",
    "        grid search\n",
    "            rolling cv of train and predict\n",
    "            list of cv score\n",
    "            list of models \n",
    "        Best params from smallest error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = auto_arima(rt_1_D_train, seasonal=False, trace=True, error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "model.get_params()\n",
    "in_sample_predictions = model.predict_in_sample()\n",
    "model.fit(rt_1_D_train)\n",
    "Evaluate the model on the test data\n",
    "predictions = model.predict(n_periods=len(test_data), exogenous=test_data.drop('target_variable', axis=1))\n",
    "Do something with the predictions\n",
    "plot the predictions for validation set\n",
    "plot_time_series(rt_1_D_train, in_sample_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corss valid and train auto arima\n",
    "# Define the rolling forecast cross validation object\n",
    "\n",
    "# cv_results = cross_validate(\n",
    "#     model,  # the auto_arima model\n",
    "#     rt_1_D_train,  # the target variable\n",
    "#     cv=rfcv,  # number of cross-validation folds\n",
    "#     scoring = evaluate,  # return the fitted models\n",
    "#     verbose=2  # print progress messages\n",
    "# )\n",
    "# Iterate over the splits and fit an auto arima model to each split\n",
    "model_params = []\n",
    "evaluation_results = []\n",
    "models = []\n",
    "for train_index, test_index in rfcv.split(rt_1_D_train):\n",
    "    train_data = rt_1_D_train.iloc[train_index]\n",
    "    test_data = rt_1_D_train.iloc[test_index]\n",
    "\n",
    "rfcv = RollingForecastCV(\n",
    "    h=170,  # forecast horizon\n",
    "    step=30,  # step size\n",
    ")\n",
    "for train_index, test_index in rfcv.split(data):\n",
    "    train_data = data.iloc[train_index]\n",
    "    test_data = data.iloc[test_index]\n",
    "    model = train_model(train_data, config)\n",
    "    prediction = model_predict(model, train_data, cfg)\n",
    "    predictions.append(prediction)\n",
    "    evaluation_result = evaluate(test_data, prediction)\n",
    "    evaluation_results.append(evaluation_result)\n",
    "\n",
    "\n",
    "#     model = auto_arima(train_data, seasonal=False, trace=True, error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "#     model.fit(train_data)\n",
    "#     models.append(model)\n",
    "#     model_params.append(model.get_params())\n",
    "#     in_sample_predictions = model.predict_in_sample()\n",
    "#     evaluation_result = evaluate(in_sample_predictions, train_data)\n",
    "#     evaluation_results.append(evaluation_result)\n",
    "\n",
    "#roling window cross vlaidation for model traning and grid search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(data, cfg_list):\n",
    "    scores_and_models = {}\n",
    "    for cfg in cfg_list:\n",
    "        score, model = walk_forward_validation(data, cfg)\n",
    "        scores_and_models[cfg] = {'score': score, 'model': model}\n",
    "    \n",
    "    # Calculate mean and standard deviation of scores\n",
    "    scores = [v['score'] for v in scores_and_models.values()]\n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "    \n",
    "    return scores_and_models, mean_score, std_score\n",
    "\n",
    "\n",
    "def train_model(train, config):\n",
    "    order = config\n",
    "    model = ARIMA(train, order=order)\n",
    "    model_fit = model.fit()\n",
    "    return model_fit\n",
    "\n",
    "def model_predict(model, start, end):\n",
    "    return model.predict(start=start, end=end)\n",
    "\n",
    "def evaluate(test_data, prediction):\n",
    "    return measure_rmse(test_data, prediction)\n",
    "\n",
    "def walk_forward_validation(data, cfg):\n",
    "    rfcv = RollingForecastCV(h=170, step=30)\n",
    "    evaluation_results = []\n",
    "\n",
    "    for train_index, test_index in rfcv.split(data):\n",
    "        train_data = data[train_index]\n",
    "        test_data = data[test_index]\n",
    "        model_fit = train_model(train_data, cfg)\n",
    "        prediction = model_predict(model_fit, start=len(train_data), end=len(train_data)+len(test_data)-1)\n",
    "        evaluation_result = evaluate(test_data, prediction)\n",
    "        evaluation_results.append(evaluation_result)\n",
    "\n",
    "    return np.mean(evaluation_results), model_fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_predictions = model.predict_in_sample()\n",
    "plot_time_series(rt_1_D_train, in_sample_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = cv_results['test_score']\n",
    "min_rmse_dict = min(test_scores, key=lambda x: x['rmse'])\n",
    "print(min_rmse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = cv_results['test_score']\n",
    "min_rmse_dict = min(test_scores, key=lambda x: x['rmse'])\n",
    "print(min_rmse_dict)\n",
    "# Get the order of the best model\n",
    "best_model_idx = cv_results['test_score'].argmax()\n",
    "best_model = cv_results['estimator'][best_model_idx]\n",
    "best_order = best_model.order\n",
    "\n",
    "# Print the order of the best model\n",
    "print(f\"The order of the best auto_arima model is {best_order}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for training and evaluation of model training for trad models\n",
    "# just passing training data to the model\n",
    "def train_and_evaluate_model(predict_funct, train_data, test_data):\n",
    "    # Train and test the model\n",
    "    y_pred, fitted_model = predict_funct(X_train, y_train)\n",
    "\n",
    "    # Evaluate the predictions\n",
    "    evaluation_result = evaluate(y_pred, y_test)\n",
    "\n",
    "    return evaluation_result, fitted_model\n",
    "\n",
    "\n",
    "train_and_evaluate_model(fit_arima, ts_1_imp[[:]], test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_data, test_data in rolling_forecast_origin_split(X, window_size=30):\n",
    "    # Get the fitting function for the current model\n",
    "    predict_funct = MODEL_FUNCTIONS[model_name]\n",
    "\n",
    "    # Train, test and evaluate the model\n",
    "    evaluation_result, fitted_model = train_and_evaluate_model(predict_funct, train_data, test_data)\n",
    "\n",
    "    # You can now access the fitted model object and use its methods\n",
    "    print(f\"Fitted model: {fitted_model}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#residual\n",
    "# Split the data into features and labels\n",
    "X, y = dataset_combination[0], dataset_combination[1]\n",
    "# Iterate through the rolling forecast origin split\n",
    "for X_train, y_train, X_test, y_test in rolling_forecast_origin_split(X, y, window_size=30):\n",
    "\n",
    "    # Perform residual analysis\n",
    "    residual_analysis(model_name, test_func, test_data)\n",
    "\n",
    "    # Perform diagnostics\n",
    "    diagnostics(model_name, test_func, test_data)\n",
    "    print(f\"Cross-validation result: {cv_result}\")\n",
    "    print(f\"Residual analysis result: {residual_result}\")\n",
    "    print(f\"Diagnostics result: {diagnostics_result}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering ML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML\n",
    "- RF\n",
    "- SVM\n",
    "- LightGBM\n",
    "- LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2\n",
    "- ARIMA\n",
    "- GARCH (depending on correlation of residuals fo ARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML\n",
    "- RF\n",
    "- SVM\n",
    "- LightGBM\n",
    "- LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H1,H2\n",
    "\n",
    "Optimization of best model\n",
    "\n",
    "Residual and diagnostic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trad\n",
    "- VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML\n",
    "- RF\n",
    "- SVM\n",
    "- LightGBM\n",
    "- LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H4\n",
    "- VAR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H3,H4\n",
    "\n",
    "Optimization of best model\n",
    "\n",
    "Residual and diagnostic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast validation\n",
    "- H1\n",
    "- H2\n",
    "- H3\n",
    "- H4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
