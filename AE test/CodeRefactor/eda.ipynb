{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda_fucntions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load non-imputed data and calculate returns\n",
    "ts1_o, ts2_o, rt_1_o, rt_2_o = load_data_and_calculate_returns(\n",
    "    \"Test_data.csv\", imputed=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot nomrliased prices of normliased and both series with their returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(ts1_o, ts2_o,'raw')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate seasonal decompositions on hourly, daily and weekly time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality_analysis(ts1_o, ts2_o, rt_1_o, rt_2_o)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform spectral analysis on both series:\n",
    "Generate and plot Lomb-Scargle periodogram to detect and quantify periodic signals in the time series data.\n",
    "Plot the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF). The ACF shows the correlation of a series with its own lags and can be used to identify the presence of random walk (unit root). The PACF displays the correlation between the series and its lags that is not explained by previous lags.\n",
    "The Ljung-Box test is performed to determine whether the returns are not correlated or randomly distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_analysis(ts1_o, ts2_o, rt_1_o, rt_2_o)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform distribution analysis on log returns:\n",
    "Firstly, display the univariate statistics to provide an overview of data characteristics. Next, compute and display the rolling statistics over one-hour intervals to identify trends and patterns in the dataset.\n",
    "Generate and plot histograms and Kernel Density Estimates (KDE) for each data column, enabling visual inspection of the data distribution. Also, plot a daily boxplot to detect outliers and assess data spread and skewness.\n",
    "Perform a normality analysis to test whether the data follows a Gaussian distribution. Lastly, conduct a stationarity test on each data column to ascertain whether the mean and standard deviation of the series remain constant over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_analysis(rt_1_o, rt_2_o)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform volatility clustering analysis on both return series:\n",
    "Visualize the squared and absolute returns for each time series to identify patterns of volatility. \n",
    "Implement the ARCH LM test and Ljung-Box test on both squared and absolute returns. The ARCH LM test examines for autoregressive conditional heteroskedasticity, a form of volatility clustering, whereas the Ljung-Box test probes for auto-correlation indicative of volatility clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility_clustering_analysis(rt_1_o, rt_2_o)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform outlier analysis on the return series:\n",
    "The squared returns are calculated for both series as a measure of volatility. These squared returns are then standardized to enable efficient clustering.\n",
    "\n",
    "DBSCAN clustering is applied to these standardized squared returns, which is an unsupervised machine learning technique capable of identifying dense regions or 'clusters' in the data, with sparse regions in between seen as noise.\n",
    "Outliers are subsequently extracted from these clusters based on their distance from the center. \n",
    "\n",
    "Plot the original returns and the squared returns with the detected outliers highlighted. This provides a visual representation of where the outliers are located in the time series data.\n",
    "\n",
    "Conduct a comparison of the outliers in both series to identify if there are common outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_analysis(rt_1_o, rt_2_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load imputed data and calculate returns\n",
    "ts1_i, ts2_i, rt1_i, rt2_i = load_data_and_calculate_returns(\n",
    "    'interpolate_clean_df.csv', imputed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputed data\n",
    "plot_series_and_returns(ts_1, 'ts1_imputed')\n",
    "plot_series_and_returns(ts_2, 'ts2_imputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seasonality analysis\n",
    "print(\"Seasonality analysis for ts1:\")\n",
    "analyse_seasonality(ts1, 'ts1', freq_list=['H', 'D', 'W'])\n",
    "\n",
    "print(\"Seasonality analysis for ts2:\")\n",
    "analyse_seasonality(ts2, 'ts2', freq_list=['H', 'D', 'W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#spectral analysis\n",
    "print(\"Spectral analysis for rt1:\")\n",
    "spectral_analysis(rt1, 'ts1', freq_list=['H', 'D', 'W'])\n",
    "\n",
    "print(\"Spectral analysis for rt2:\")\n",
    "spectral_analysis(rt2, 'ts2', freq_list=['H', 'D', 'W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution analysis\n",
    "rt = pd.concat([rt1, rt2], axis=1)\n",
    "print(\"Distribution analysis for log returns:\")\n",
    "analyse_distribution(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#volatility clustering analysis\n",
    "print(\"Volatility clustering analysis for rt1:\")\n",
    "assess_and_plot_volatility_clustering(rt1)\n",
    "\n",
    "print(\"Volatility clustering analysis for rt2:\")\n",
    "assess_and_plot_volatility_clustering(rt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier analysis\n",
    "print(\"Outlier analysis for rt1 and rt2:\")\n",
    "rt1_d = rt1.resample('H').mean().dropna()\n",
    "rt2_d = rt2.resample('H').mean().dropna()\n",
    "analyse_outliers(rt1_d, rt2_d, 'Hourly')\n",
    "rt1_d = rt1.resample('D').mean().dropna()\n",
    "rt2_d = rt2.resample('D').mean().dropna()\n",
    "analyse_outliers(rt1_d, rt2_d, 'Daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputed data\n",
    "plot_series_and_returns(ts_1, 'ts1_imputed')\n",
    "plot_series_and_returns(ts_2, 'ts2_imputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
