{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelling_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating log returns\n",
      "Calculating log returns\n"
     ]
    }
   ],
   "source": [
    "models_and_param_grids = [\n",
    "    {\n",
    "        'model': DecisionTreeRegressor(random_state=42),\n",
    "        'param_grid': {\n",
    "            'max_depth': [None, 10, 20, 30, 50],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'max_features': ['auto'],\n",
    "            'min_samples_leaf': [1, 3, 5, 10]\n",
    "        },\n",
    "        'model_name': 'CART',\n",
    "    },\n",
    "    {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'param_grid': {\n",
    "            'n_neighbors': [3, 5, 7, 9, 11],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto'],\n",
    "            'leaf_size': [10, 30, 50],\n",
    "        },\n",
    "        'model_name': 'KNN',\n",
    "    },\n",
    "    {\n",
    "        'model': lgb.LGBMRegressor(max_depth=-1, random_state=42),\n",
    "        'param_grid': {\n",
    "            'lgbmregressor__n_estimators': [100, 200],\n",
    "            'lgbmregressor__learning_rate': [0.01],\n",
    "            'lgbmregressor__max_depth': [5, 10, 20],\n",
    "            'lgbmregressor__num_leaves': [35, 50],\n",
    "        },\n",
    "        'model_name': 'GBR',\n",
    "    },\n",
    "    {\n",
    "        'model': xgb.XGBRegressor(random_state=42),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'min_child_weight': [1, 3, 5],\n",
    "        },\n",
    "        'model_name': 'XGB',\n",
    "    },\n",
    "    {\n",
    "        'model': RandomForestRegressor(random_state=42),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [10, 50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'max_features': ['auto'],\n",
    "        },\n",
    "        'model_name': 'RF',\n",
    "    },\n",
    "    # {\n",
    "    #     'model': MLPRegressor(random_state=42),\n",
    "    #     'param_grid': {\n",
    "    #         'hidden_layer_sizes': [(50,), (100,), (50, 50),(100, 100), (50, 50, 50), (100, 100, 100), (50, 50, 50, 50), (100, 100, 100, 100)],\n",
    "    #         'activation': ['tanh', 'relu', 'logistic'],\n",
    "    #         'solver': ['sgd'],\n",
    "    #         'alpha': [0.00005, 0.0005, 0.005],\n",
    "    #         'early_stopping': [True],\n",
    "    #         'max_iter': [600],\n",
    "    #         'shuffle': [False],\n",
    "    #     },\n",
    "    #     'model_name': 'MLP',\n",
    "    # },\n",
    "    #     {\n",
    "    #     'model': GaussianProcessRegressor(random_state=42),\n",
    "    #     'param_grid': {\n",
    "    #         'kernel': [RBF(), DotProduct()+ WhiteKernel()],\n",
    "    #         'alpha': [1e-10, 1e-5, 1e-2, 1],\n",
    "    #         'n_restarts_optimizer': [0, 1, 3],\n",
    "    #     },\n",
    "    #     'model_name': 'GPR',\n",
    "    # },\n",
    "]\n",
    "\n",
    "file_name_raw = \"Test_data.csv\"\n",
    "file_name_clean = \"imputed_df.csv\"\n",
    "\n",
    "# load data, transform and split\n",
    "ts_raw = load_data_file(file_name_raw)\n",
    "ts_imputed = load_data_file(file_name_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 'D'\n",
    "n_trials = 100\n",
    "#default process is false for log returns\n",
    "ts_raw_transformed = transform_data(ts_raw, frequency, do_log_returns=False)\n",
    "ts_imputed_transformed = transform_data(ts_imputed, frequency, do_log_returns=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark prediction using geometric brownian motion. \n",
    "S[t] = S[t-1] * (1 + ε) \n",
    "S[t] is the stock price at time t\n",
    "S[t-1] is the stock price at time t-1\n",
    "ε is a normally distributed random variable with mean 'mu' and standard deviation 'std'      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_predictions_and_plot(ts_raw_transformed, n_trials)\n",
    "run_predictions_and_plot(ts_imputed_transformed, n_trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = '2011-12-31'\n",
    "frequency = 'D'\n",
    "LOG_RETURNS = True\n",
    "\n",
    "\n",
    "test_size = 14\n",
    "n_splits = 30\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits, test_size=test_size)\n",
    "lags = 3\n",
    "\n",
    "ts_raw_transformed = transform_data(ts_raw, frequency, do_log_returns=LOG_RETURNS)\n",
    "ts_imputed_transformed = transform_data(ts_imputed, frequency, do_log_returns=LOG_RETURNS)\n",
    "train_raw, test_raw = split_data(ts_raw_transformed, split_date)\n",
    "train_imp, test_imp = split_data(ts_imputed_transformed, split_date)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypotheses models testing for four hypotheses with four cases of features:\n",
    "- missing vlaues removed without outliers marked\n",
    "- missing values removed with outliers marked\n",
    "- missing values imputed without outliers marked\n",
    "- missing values imputed with outliers marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_results = test_hypothesis('H1', 'ts1', 'ts1', models_and_param_grids, tscv, lags, train_raw, test_raw, train_imp, n_splits, test_size)\n",
    "h2_results = test_hypothesis('H2', 'ts2', 'ts2', models_and_param_grids, tscv, lags, train_raw, test_raw, train_imp, n_splits, test_size)\n",
    "h3_results = test_hypothesis('H3', 'ts1', 'ts2', models_and_param_grids, tscv, lags, train_raw, test_raw, train_imp, n_splits, test_size)\n",
    "h4_results = test_hypothesis('H4', 'ts2', 'ts1', models_and_param_grids, tscv, lags, train_raw, test_raw, train_imp, n_splits, test_size)\n",
    "\n",
    "plot_all_experiment_results_comparison(h1_results, 'H1')\n",
    "plot_all_experiment_results_comparison(h2_results, 'H2')\n",
    "plot_all_experiment_results_comparison(h3_results, 'H3')\n",
    "plot_all_experiment_results_comparison(h4_results, 'H4')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
